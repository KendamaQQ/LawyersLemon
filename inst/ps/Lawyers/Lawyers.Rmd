
```{r 'check_ps', include=FALSE}

user.name = '' # set to your user name

# To check your problem set, run the 
# RStudio Addin 'Check Problemset'

# Alternatively run the following lines
library(RTutor)
ps.dir = getwd() # directory of this file
ps.file = 'Lawyers.Rmd' # name of this file
check.problem.set('Lawyers', ps.dir, ps.file, user.name=user.name, reset=FALSE)
```


# Selection and Success of Lawyers

Author: Artemij Cadov

## Introduction




### Hello there!

Since the landmark case [*Gideon v. Wainwright*](https://supreme.justia.com/cases/federal/us/372/335/), and it's application on the Sixth Amendment, states are required to provide an attorney to defendants in criminal cases who are unable to afford their own counsel. Thereupon, two different approaches for defending indigent criminal accused emerged: public defender systems and assigned counsel programs. While public defenders are government employees who only represent indigent clients, assigned counsels are independent private attorneys who enroll into a selection pool. Hence, public counsels are typically paid by salary rather than at a hourly rate. By contrast assigned attorneys (also called Criminal Justice Act (CJA) panel attorneys) are generally paid by the local government on a case-by-case basis after their services are rendered.  While in 79 % of all US jurisdictions both approaches are intertwined, this problem set just focuses on Bexar County, Texas, where assigned attorneys are used almost exclusively. Obviously, defendants with the means can always hire their own counsel for the purpose of criminal defense. In 2014, only about 24 % of cases in Bexar County were able to retain their own counsel. The ability of some defendants to hire their own attorney, coupled with the fact that many defendants do not have the means to pay for legal representation, raises, inter alia, the question of attorney effectiveness.

---

#! addon__quiz__entry question

---


This is an interactive problem set, which is part of my master's thesis at Ulm University. 
It examines, why assigned as opposed to retained attorneys achieve relatively worse outcomes for their clients.
But there is far more information out there, that we can consider in answering this question, which is our **research question**.
Like always when learning new things, answering questions leads initially to even more questions. Like, what is the appropriate model to answer the research question, which covariates shall be included in the model and how to implement it in R?
Don't worry, if you are interested in these questions, this problem set will ease the way to answer them all. 

The analysis is based on the article ["Is Your Lawyer a Lemon? Incentives and Selection in the Public Provision of Criminal Defense"](https://www.mitpressjournals.org/doi/abs/10.1162/rest_a_00891) by *Agan, Freedman and Owens* (2019). Be aware, that there is also an earlier version, respectively [working paper](https://www.nber.org/papers/w24579) out there, which is also important for this problem set, since it contains additional analysis to the main paper. I will refer to the main article simply as "Agan et al." or "the authors" from now on and will state explicitly, if a look at the working paper is necessary.

You will derive most results interactively using the programming language R. This means that you must enter your own R code from time to time. This way, you can enhance your R programming skills while reproducing the results from an interesting economic article. I will explain some R functions when you need them, but you are expected to have basic R skills. If you need an introduction to programming in R, you can, for example, have a look at [R for Beginners](https://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf). Below, you can find more information on how to solve the problem set. If you are ready, proceed to Exercise 1 and get started!

---

## Exercise Content


1. Descriptive Statistics
    
2. Investigate Lawyer Heterogeneity
  
    2.1 Unconditional Assigned Counsel Penalty
  
    2.2 Assigned Counsel Penalty

3. Decomposition of Assigned Counsel Penalty

    3.1 Case Characteristics and Adverse Selection
    
    3.2 Matching Preferences
    
    3.3 Moral Hazard

4. Investigating Recidivism

5. Conclusion

6. References


---

### How to solve this problem set


Solving the problem set is straightforward. Here is a short explanation of the elements you may encounter.

- Code Chunks: They are used to enter and run R code. You must solve a code chunk before you can interact with the following one. To interact with code chunks, there are several buttons:

    + `edit`: After pressing this button, you can enter your R code into the chunk. You always have to press the edit button on the first code chunk of an exercise.
    + `check`: After entering your solution, you have to press check to run your code and check whether your answer is correct. Sometimes, the correct answer is already entered in the chunk, so you only have to press check.
    + `hint`: If you need help solving the chunk, you can press this button to get a hint.
    + `run chunk`: This button runs the code chunk without checking whether it is correct.
    + `data`: This button is a link to the Data Explorer, in which you can view data sets and look at variable descriptions.
    + `solution`: Pressing this button enters the sample solution into the code chunk.
<br>
- Tasks: They describe, what is getting done in the succeeding code chunk. Sometimes the code is already provided, in this circumstance, you will be asked just to press `check` and continue. 

- Quizzes: It is not necessary to solve the quizzes to be able to continue with the problem set, but they contribute to the overall understanding of the topic.

- Info Boxes: They contain additional information, which is not necessary for solving the problem set, for example explanations of R functions or mathematical proofs.

To navigate through the problem set, you can use the button `Go to next exercise...` at the bottom of the page or the menu bar at the top. It is possible to solve each exercise without solving the previous ones; however you are encouraged to solve the exercises in the specified order as they follow a didactic structure.


## Exercise 1 -- Descriptive Statistics

In this exercise we will have a look at basic data manipulation techniques. In parallel you have the possibility to get familiar with the data by computing some insightful statistics. Subsequently, we will replicate and look at some descriptive statistics from the author's paper. Overall, this exercise aims at preparing you for the more advanced exercises afterwards by combining both, programming knowledge and information on the topic that we study. 

The first necessary step for every sophisticated analysis is to explore the data. Agan et al. merged multiple data sources into one data set, which consists of **64209 observations** on over 600 variables. This might seem overwhelming at first place, but be appeased with the fact, that our analysis necessitates just a subsample of 68 variables. The data provides information about cases, whereat **each observation corresponds to a case**. Each case contains defendant and attorney characteristics as well as information on the defendants block group, assembled from the ACS 2009-2013 (American Community Survey). 

Without further ado, let's now have a look into the actual data.

**Task:**
Use the `readRDS` command to load the data set and store it in a variable called `Lawyers`.

```{r "1"}
# Reading the data can take a little bit of time, so be patient.
dat <- ___("Lawyers.rds")
```


The two main variables, that we are going to use in our analysis are `guilty` and `appointed`. Both take only the two values 0 and 1. In the case of `guilty`, 0 indicates, that the defendant wasn't convicted and 1 stands for conviction. In the case of `appointed`, 0 indicates, that the attorney was retained by a defendant and 1 means the attorney was assigned to an indigent defendant. Let's take a look at both variables. 

**Task:** 
Use the function `select()` from `dplyr` to select the variables `guilty` and `appointed` and save them in a variable `selected`. Afterwards, use the `head()` function to print out the first six observations in `selected`. 

```{r "1__2"}
# First load the dplyr package
library(dplyr)
selected <- dat %>% select(___)
head(selected)
```

info("dplyr") # Run this line (Strg-Enter) to show info

info("%>%") # Run this line (Strg-Enter) to show info

Let's find out more about `appointed` and `guilty`. Since they are both variables with the only values 0 and 1, we can compute the average and interpret it as percentage rate. 

**Task:**
Use the `mean()` function along with `appointed` and `guilty` to compute the assignment and conviction rate. The code for the assignment rate is already provided, so you just have to compute the `mean()` of `guilty`.

```{r "1__3"}
# Firstly, let's compute the assignment rate
mean(dat$appointed)

# Secondly, fill in the right argument to compute the conviction rate
mean(___)
```

The result reveals that 63 % of felony cases in Bexar County between 2005 and 2014 were negotiated by assigned counsels and 48 % of clients were convicted. To know how many people were convicted overall isn't very informative, if we are interested in studying differences between two groups (retained vs. assigned). Before we compute the conviction rate based on counsel appointment, try to guess how big the gap in conviction rates between retained and assigned counsels is.

---

#! addon__quiz__Gap in Conviction Rates

---

**Task:**
In this task we will become familiar with `group_by()` and `summarise()` from `dplyr`. 
Firstly, provide `appointed` as argument to `group_by()`. Since `appointed` only takes two distinct values (0 and 1) the `group_by()` function yields two groups. Secondly, use `summarise()` to compute the `conviction_rate` and the number of `observations` in each group. You already know how to compute the conviction rate from the last exercise. The number of `observations` in each group can be computed with the help of `n()`. The code is mostly provided, you just need to fill in the missing parts within `summarise()`.

```{r "1__4"}
dat %>% 
group_by(appointed) %>% 
summarise(conviction_rate=___,
          observations=___) 
```

As you see, there are 23559 cases in our data with an attorney being retained and 40650 times an indigent defendant got a counsel assigned. But more interesting is that the conviction rate obviously differs in both groups. Defendants with an assigned attorney are **18.3 percentage points** more likely to be found guilty. In this context it's important to distinguish between a percent change and a percentage point change. We could also state the result as a percent change: Defendants with an assigned attorney are **50.3 %** more likely to be found guilty. By looking at the numbers, it's easy to realize, that there is a huge difference. Both conviction rates are stated in percentage points, so the spread between them is also stated in percentage points. However, if we divide this difference by the conviction rate of defendants with a retained counsel, we have computed the change in percent. Note, that it is also possible to divide the percentage point difference by the conviction rate of defendants with an assigned attorney. Obviously, we would get another solution, which emphasizes the importance to be clear, which value is used in the denominator.   

We want also to obtain some information regarding the attorneys in our data set. For example, how many distinct counsels does the data comprise? How many of them have served both as assigned and retained attorneys? Are there systematic differences in attorney characteristics between counsels who handle assigned as opposed to retained cases? These are vital issues, because they give us a glimpse on the answer to our **research question**. Let's tackle them one by one. 

**Task:**
At first, compute the number of distinct attorneys and the number of cases each of them handled. Each attorney has an unique numerical code, attributed by the State Bar, which is saved in the variable `attybarcard`. Use this variable as argument to the function `count()` (more information in the info box), which is also shipped with `dplyr` and is more handy for such tasks, than building a pipe yourself.   
Also, compute the number of rows with `nrow()`. This will show us how many attorneys there are in total in our data.
Finally, use `head` with `counting` as argument to show the first six results. 

```{r "1__5"}
# Use attybarcard to count the number of observations (=cases) for each distinct attorney
counting <- count(dat, ___)

# Compute the number of attorneys in our data
nrow(counting)

# Use counting as argument to head to print out the first six values
head(___)
```


info("count()") # Run this line (Strg-Enter) to show info

We obtain, that there are 726 different lawyers in our data.
 And apparently the number of cases differs dramatically among them. 

---

#! addon__quiz__Most Cases

---

Let's validate the right answer from the quiz. 

**Task:**
Use our prior defined variable `counting` along with the function `arrange()` from `dplyr` to arrange the column `$n`. Note that arrange takes as first argument the data and as second argument the column. By default `arrange()` arranges the column in ascending order. In order to arrange the column in descending order you need to prefix a negative sign in front of the second argument. Eventually, use the `head()` function to limit the output to the first six rows. 

```{r "1__7"}
# You need to supply the second argument to the function arrange
# Don't forget the negative sign in order to arrange the data in descending order
head(arrange(counting,___))
```

Handling over 800 cases over a time period of 9 years (remember that our sample spans the years 2005-2014) is quite impressive. Let's see, if we can find out more about this attorney.

---

#! addon__quiz__Retained or Assigned

---

Let's elaborate the right answer to the quiz.

**Task:**
Use a pipe to solve this task. Start with our data `dat`, `filter()` by the `attybarcard` of the attorney in question and `select()` only the column `appointed`. Finally, compute the assignment rate within `summarise`.

```{r "1__8"}
# We start the pipe with our data set dat
dat %>% 
# Provide the Attorney Bar Card Number as filter condition  
  filter(attybarcard==___) %>% 
# Use appointed as the argument to select
  select(___) %>% 
# Finally, compute the assignment rate
 summarise(assignment_rate=___)

```

As it can be seen, the attorney in question was assigned in 94% of all cases he resolved. Are attorneys, who resolved more cases more often assigned in general? And if so, why? One reason might be, that they handle cases, which are simpler to resolve. But another explanation could be, that they exert less effort if assigned and hence resolve cases quick but at the expense of their clients. We won't answer this question now, but if you keep going you will encounter the answers.   

---

#! addon__quiz__Attorneys Assigned at All

---

That's good to know, but a little bit unprecise. Let's compute the actual share of attorneys, who work as both, assigned and retained.

**Task:**
Solve this task utilizing a pipe. First use `group_by()` along with `attybarcard` to define 726 groups, one for each attorney. Then, use `summarise()` to calculate the assignment rate for each group and save it in a variable `ratio.both`. Afterwards, use `filter()` to filter out all groups, where `ratio.both` is 0 or 1 (just retained or just assigned cases handled). Finally, compute the number of rows with `nrow()`.

```{r "1__9"}
# Start the Pipe
dat %>% 
# Group by attybarcard
  group_by(___) %>% 
# Compute assignment rate for each group
  summarise(ratio.both = ___) %>% 
# The filter condition is already supplied
  filter(ratio.both > 0 & ratio.both < 1) %>% 
# Count the number of attorneys, who work as both
  nrow()
```

So, there are 492 attorneys, who handle both type of cases.   
But now, let's look at overall characteristics between retained and assigned cases. Try to answer the questions below. We will take a thorough look at the solution afterwards. 

---

#! addon__quiz__Multiple Choice

---

After answering the questions, let's validate the solutions by taking a look at the means of certain characteristic variables. The descriptives are represented in an appealing layout by exploiting [swiper](https://swiperjs.com).

**Task:**
Simply click `check` and look at the tables. You can switch between them either by wiping with your mouse or clicking on the radio buttons beneath.

```{r "1__10",results='asis'}
includeHTML("characteristics.html")
```

<br>
<br>
Please notice that this cube of tables following *figure 2* from the paper and focuses on the most remarkable descriptives. All values in the cube represent means. Again, have a look at *figure 2*, if you are also interested in the corresponding standard deviations. Obtaining this numbers is by no means difficult, so let's exemplify one value, e.g. the white characteristic in the defendants table.

**Task:**
In order to replicate the statistic use the `group_by()` function along with `summarize()`. You need to fill in `appointed` as the argument to `group_by()`. Note, that the remaining code is already provided. 

```{r "1__11"}
# Supply the right variable to the group_by() function
dat %>% 
  group_by(___) %>% 
  summarize(white=mean(white))
```


Now, let's discuss the tables thoroughly. 
Looking at the first Table it can be noticed at a glance that in relative terms attorneys get retained more often by white defendants compared to black defendants. While the Hispanic share is paramount in both groups, there can't be detected a similar difference as in the other two defendant characteristics. Remember, at this point we can't and shouldn't aim to answer what drives this (missing) differences, we just might get a feeling, that there is some hidden explanation yet to unravel. Indeed, we can easily explain why the share of Hispanic defendants is in both groups so large. Bexar County comprises San Antonio, which is the seat of the county and place to 1.7 million people (in 2010). The County is ethnically diverse, in 2010 59.1% identified as Hispanic, 29.5% as White and 8.2% of the population identified as African American. In this context, the percentages in the retained group mirror the respective population fractions, with a slightly elevated value on the side of African American defendants. Whereas in the assigned group, despite Hispanic defendants, black defendants are overrepresented in favor of white defendants. 
Both, previous convictions and poverty rate, are drastically higher in the appointed group as well. Let's rotate the cube and look at the second table.

Apparently, the share of male attorneys is higher, when the counsel is retained. The years of experience is also higher in the retained group and the amount of previous cases is nearly doubled contrary to the average value in the assigned group. Computing the previous cases per year, the retained group (32) is still ahead of the assigned group (22). Further, there seems so be a preference towards retaining an attorney of same ethnical background in the private market. Finally, let's look at the *outcome characteristics* in the last table. 

The authors analyzed in their paper mainly four outcome variables: **Convicted**, **Dismissed**, **Deferred Adjudication** and **Incarcerated given Conviction**. In this problem set we will mainly focus on *Convicted*. The proceeding is almost identical, the only changing factor in the models we will study is the outcome variable itself. Of course, we will provide the results to the other three variables subsequently, e.g. in an info box. But now let's eventually turn to the figures. By now, you may already expect, that the outcome of felony cases is detrimental to defendants with appointed counsels in opposition to retained attorneys. Still, a round about 18 percentage points higher conviction rate is remarkable, as well as 14 percentage points lower rate of dismissed cases and something that surely deserves further inquiry. Similarly, indigent defendants face a higher sentence and on average higher fines. Note that indigence is defined upon net income. We need to remark though, that *Convicted* is indeed a summary. It consists of all guilty pleas, pleas of nolo contendere and actual convictions at trial. However, most cases get resolved by guilty pleas and pleas of nolo contendre. Only a minority of defendants get convicted at trial. 

Table 2 suggested, that there is a disparity in the experience between the two lawyer groups. Since we haven't looked at a chart yet, let's investigate further into experience inequalities and learn something about visualization in R. The aim of the next tasks is so replicate the results in *figure 1 A* of the authors paper.

**Task:**
The variable `experience` indicates the years in practice since attorney bar admission. A `summary()` shows, that the values range from -3 to 41. Define a second variable `exp.fig`, that recodes all values below zero as `NA` and all values above 35 as 35. Use the `ifelse()` function and the intermediate variable `exp.int` to accomplish the task. 

```{r "1__12"}
# Firstly, mark all values beneath zero as NA (code already provided)
exp.int <- ifelse(dat$experience>=0, dat$experience, NA)

# Analogous, mark all values over 35 as 35 by using ifelse() again
dat$exp.fig <- ifelse(exp.int < 35, ___, ___)

```

The variable `exp.fig` will be the x variable in our plot. But we are still necessitating a y variable. Unfortunately, this one isn't so easy to determine, but we already acquired the knowledge to solve the tasks.   
The approach is first to group by the attorneys and their experience to compute the mean appointed rate and then to group by the experience only and compute the overall fraction of cases assigned per year of experience. 

**Task - Step 1:**
Solve this task with the help of a pipe, which uses the `group_by()` and `mutate()` function. 
The `mutate()` function can be used similar to `summarize()` with the distinction, that it appends the computed variables automatically at the end of our data. 
Firstly, `group_by()` `attybarcard` and `exp.fig`. 
Secondly, compute the variable `pct.appt.exp` as the mean of appointed cases grouped by attorney and experience.
Additionally compute `n.atty.exp`, which incrementally counts the number of observations in each group with the help of `row_number()` from `dplyr`. 

```{r "1__13"}
# We start the pipe with our data - dat
dat <-  dat %>% 
# Now, fill in the two grouping variables
  group_by(___, ___) %>% 
# Compute the assignment rate on the right-hand side of pct.appt.exp 
# Note, that we computed the assignment rate multiple times by now
  mutate(pct.appt.exp = ___, 
# Finally, we count the rows in each group (code already provided)
         n.atty.exp=row_number())
```

Let's get a feel for our computation by looking at the most experienced lawyer again. The code is already provided, just click `check`.

```{r "1__14"}
# Show computations for attorney with most cases resolved
dat %>% 
  filter(attybarcard==15278630) %>% 
  select(attybarcard, exp.fig, pct.appt.exp, n.atty.exp) %>% 
  arrange(exp.fig) %>% 
  group_by(exp.fig) %>% 
  summarise(pct.appt.exp=mean(pct.appt.exp), n.atty.exp=max(n.atty.exp))
```

The `tibble` shows for each group (experience years 16-25) the assignment rate in `pct.appt.exp` and the number of cases in `n.atty.exp`. Note however, that this is an aggregated view. For example, since there are 22 cases the attorney handled with 16 years of experience, we have also 22 rows for the newly defined variables in our data `dat`. By clicking on `data` above the chunk you can obtain a more detailed presentation of the data. Otherwise, proceed with the next task (step 2).

**Task - Step 2:**
This is just an auxiliary step. Generally, an attorney looks after many cases during a year, which guarantees us, that we have indeed multiple observations when grouping by attorney AND experience. This is essential to compute the mean in the preceding step. However, `mutate()` adds this value to every case in our data, not just on a group level, although we need it just once per group to carry on. We therefore compute the intermediate variable `int.appt.exp`, which uses `n.atty.exp` to set just the first value in each group to the value of `pct.appt.exp` and all other to `NA`. The code is already complete, just press `check`.

```{r "1__15"}
dat$pct2 <- ifelse(dat$n.atty.exp==1, dat$pct.appt.exp, NA)
```

**Task - Step 3:**
In this step we finally group and sort by `exp.fig` to compute the appointment rate for each experience year over all attorneys - `mean_pct`.
Use `exp.fig` first as argument in the `arrange()` function and afterwards as argument in the `group_by()` function to solve the task. Finally, use the `ungroup()` function to dissolve the groups.

```{r "1__16"}
dat <- dat %>% 
  arrange(___) %>% 
  group_by(___) %>% 
  mutate(mean_pct=mean(pct2, na.rm=T)) %>% 
  ungroup()
```


**Task - Step 4:**
Finally, we will plot the graph. We exploit the `ggplot2` package to do so. All you need to know about it is, that `ggplot` operates layer-based, with the first layer specifying the data, the x variable and y variable. Replenish the code in the function call `ggplot()` with our, in steps one and three, determined x and y variable.
**Note:** Take a look at the info box below for more information on `ggplot()`.

```{r "1__17"}
# Supply the correct variables to the arguments x and y in the aes function inside ggplot
ggplot(data=dat,aes(x=___, y=___))+geom_line(colour="skyblue4",size=1.25)+theme_bw()+
 labs(title="Appointment Rate per Experience",x="Experience",y="% of assigned Cases")+theme(plot.title = element_text(hjust = 0.5))
```

info("ggplot()") # Run this line (Strg-Enter) to show info

As the figure shows the share of assigned cases declines with ascending years of experience. Especially between five and ten years of experience their seems to be a slump. This corresponds to the findings in table 2, "attorney characteristics". 
By this point we could suggest that the worse case outcomes we looked at table 3 could be explained by the lower experience the assigned attorneys have on average. However, we neither know yet whether this hypothesis holds, nor do we know the reasons why lower experienced counsels preferential advocate assigned cases. So, let's jump to the next exercise and run our first model to get a deeper understanding of the topic.

<div class="garbage">
info("ignore this, this is just a garbage collector for the tables cube") # Run this line (Strg-Enter) to show info
</div>


## Exercise 2 -- Investigate Lawyer Heterogeneity

After we get some insights into the fundamentals of R as well as the paper, we will now continue to dive deeper into both. In exercise 2.1 we will run our first regression analysis. If you are already familiar with OLS that shouldn't be something, that scares you. If you are not, you will learn the basics in the exercise. Additionally, after you finished exercise 2.1 you will know, what the authors mean, when they talk about the (unconditional) assigned counsel penalty and how to estimate it. We will also discover that case characteristics, adverse selection, matching preferences and moral hazard are potential explanations for the unconditional assigned counsel penalty. Exercise 2.1 also provides an introduction of potential variables, that account for case characteristics. However, in exercise 2.2 we will run the model proposed by authors to control for all case and attorney characteristics. 

## Exercise 2.1 -- Unconditional Assigned Counsel Penalty

Before we start the exercise, we first need to read in the data again.

**Task:**
Press `check` to retrieve the data.

```{r "2_1"}
dat <- readRDS("Lawyers.rds")
```

We start this exercise off by running the following linear regression model:

$$\begin{align}
guilty_{i} = \beta_{0} + \beta_{1}*appointed_{i} + \epsilon_{i}, \qquad \text{(1)}
\end{align}$$

**Task:**
Use the `lm()` function with `guilty` as dependent and `appointed` as independent variable. Don't forget to provide our data `dat` to the `data` argument. Finally use `summary()` to produce the output table of the regression results.

```{r "2_1__2"}
# Firstly, run the model
lm.1 <- lm(___, data=___)

# Now produce the output
summary(lm.1)
```

---

Note, that we call the coefficient of `appointed` the (unconditional) **assigned counsel penalty**. The "unconditional" simply refers to the fact, that we don't have incorporated further explanatory variables besides `appointed` yet. 
Take a look at the regression output and try to answer the quiz questions afterwards.

#! addon__quiz__magnitude of appointed 1

---

#! addon__quiz__magnitude in percent

---

#! addon__quiz__significance 1

---

#! addon__quiz__conviction rate PD

---



Note, that you can find the results for the other outcome variables dismissed, deferred adjudication and incarcerated (given conviction) in the corresponding info box (along with `guilty`). While all outcome variables are pretty self-explanatory, note that deferred adjudication means that if defendants remain crime-free for a fixed period of time and comply with any other court orders, their case will be dismissed. Of course, only defendants are eligible for such a treatment, if they had little or no previous contract with the justice system in the past and who are accused of low-level offenses. 

#! start_note "other unconditional assigned counsel penalties"

The code in the chuck beneath first runs the regressions on the respective outcome variables and then produces the output with the help of `stargazer()` from the equal-named package `stargazer`. The function `stargazer()` simply produces nice looking outputs of regression results in different output formats. The code doesn't necessitate further adjustments, just press `check` and take a look at the results. 

```{r "2_1__3",results='asis'}
lm.dismissed <- lm(dismissed ~ appointed, data=dat)
lm.defadj <- lm(defadj ~ appointed, data=dat)
lm.incar <- lm(incarcerated ~ appointed, data=dat, subset=guilty==1)

stargazer(lm.1, lm.dismissed, lm.defadj, lm.incar, type="html", digits=3)
```

---

#! addon__quiz__significant coefficients

---

#! addon__quiz__the signs

---

Note, that these three outcome variables constitute together with `guilty` the main outcome variables, which Agan et al. analyzed in their paper published in the *Review of Economics and Statistics*. However, in the [working paper](https://www.nber.org/papers/w24579) you can find further analysis e.g. for the outcomes reduced charge, log of sentence in days, log of the fine and more.  

#! end_note

Now, we know how strong the relationship between `appointed` and `guilty` (or the other outcome variables) is, however, by now we don't know the reasons underlying this disparity. But we can take a look at the author's paper, where the following four potential reasons are stated: 

  <ol style="list-style-type: upper-roman">
  <li> <b> Case Characteristics: </b> It may be harder to defend indigent clients compared to non-indigent clients. </li>
  <li> <b> Adverse Selection: </b> Counsels who register to serve as assigned attorney may be less proficient. </li>
  <li> <b> Matching Mechanism: </b> The assignment approach could be adverse for indigent defendants compared with the endogenous process in the private market. </li>
  <li> <b> Moral Hazard: </b> Attorneys of indigent clients might invest less effort into their cases, relative to cases in which they are paid directly by their clients. </li>
  </ol>


First let's focus only on the case characteristics. 

---

#! addon__quiz__hadbondsman

---

Based on the quiz question, let's take a look at the respective correlations. Note, that the variable denoting, whether a bail was posted, is called `hadbondsman` in our data. It is a dummy variable, which yields 1, if a bail was posted and 0 if not. 

**Task:**
Compute the correlation between `hadbondsman` and `guilty` first. Then do the same for the variables `hadbondsman` and `appointed`. You can compute correlations directly with the function `cor()`. 

```{r "2_1__4"}
# Firstly, compute the correlation between hadbondsman and guilty

# Secondly, compute the correlation between hadbondsman and appointed

```

As you can see, `hadbondsman` is negatively correlated with both variables.     
Now, let's investigate, what happens, if we regress our main outcome variable `guilty` on `hadbondsman`.

**Task:**
Run a linear regression model with `lm()`. Use `guilty` as dependent variable and `hadbondsman` as the only regressor. 

```{r "2_1__5"}
# Run the regression first
lm.bail <- lm(formula = ___, data = dat)

# Now, produce the output
summary(lm.bail)
```

The result shows, that posting a bail decreases the predicted likelihood of being found guilty by 35.7 percentage points on average. Now, let's see, what happens to the assigned counsel penalty, if we add `hadbondsman` to our linear regression model from equation (1). 

**Task:**
Use `lm()` to run a linear regression model. Again, use `guilty` as dependent variable and `appointed` plus `hadbondsman` as independent variables. 

```{r "2_1__6"}
# Run the regression first
lm.2 <- lm(formula = ___, data = dat)

# Now, produce the output
summary(lm.2)
```

As you can see adding `hadbondsman` to our regression changes all coefficients. Firstly, the predicted effect of posting a bail decreases by 2.6 percentage points, if `appointed` is also present as regressor in the linear model. But way more important is, that the predicted assigned counsel penalty decreases from 18.3 percentage points to 7.7 percentage points due to addition of `hadbondsman`. That suggests a relationship between our treatment variable `appointed` and the case characteristic variable `hadbondsman`. Indeed, `appointed` and `hadbondsman` are negatively correlated. Thus, variation in hadbondsman is also captured by the unconditional assigned counsel penalty, if we exclude `hadbondsman` as in equation (1). On the other hand, if we include `hadbondsman` the coefficient of `appointed` only assess the variation in assignment on conviction, holding `hadbondsman` constant. Take a look at this graph, which summarizes the relationships. Note, that the dashed line between `appointed` and `hadbondsman` represents only a correlation, while the solid lines can be interpreted as causal relationships. As you can see, beneficial case characteristics lower the probability of getting convicted. However, if a defendant is indigent he doesn't have beneficial case characteristics in general, which leads to a higher probability of getting convicted. The ability to post a bail is also beneficial for the case outcome. So, if we control for it in our regression, the inverse relationship between `appointed` and beneficial case characteristics becomes less strong, which leads to a lower assigned counsel penalty. 


<br>

<center>

![Correlations between Case Characteristics, Appointed and Guilty](flowchart1.png)

</center>
*Source: Own creation.*
<br>


To emphasize this more deeply, let's do another regression. 

**Task:**
Firstly, use `lm()` to run a regression with `appointed` as dependent variable and `hadbondsman` as only regressor. Save the regression in a variable `lm.3`. Because the `lm()` function returns a object of class `lm`, we can access different regression outputs with the help of `$`, e.g. `lm.3$coefficients` retrieves just the coefficients from the regression.   
Secondly, use `lm()` again to run a regression with `guilty` as dependent variable and use the residuals from `lm.3` as independent variable. Note, that all you have to do in order to incorporate the residuals into the model is to retrieve it by `lm.3$residuals`.   
Finally, save the second regression in a variable `lm.4` and use `summary()` to print the result. 

```{r "2_1__7"}
# Run the first regression
lm.3 <- lm(formula = ___, data = dat)

# Run the second regression
lm.4 <- lm(formula = guilty ~ ___, data = dat)

# Now, produce the output
summary(lm.4)
```

As you can see, the coefficient of `lm.3$residuals` is actually the assigned counsel penalty from our model with `hadbondsman`. Why is that? The residuals, that we obtained from `lm.3` capture the variation in `appointed`, which can't be explained by `hadbondsman` in our sample. What we are left with is the unique variation in `appointed`. This procedure is also known as **partialling out** and we can call the coefficient of `appointed` the **marginal effect** on `guilty` (alternatively to assigned counsel penalty).   

Now the question arises, whether the residuals from `lm.3` really capture only the random correlation in `appointed` or is there maybe another case characteristic variable, that interferes our estimate and hence potentially explains the disparity in convictions between indigent and non-indigent defendants to some extent? As the flowchart above indicates, there could be further case characteristics, that are correlated with apppointed and guilty. But, these case characteristics might be not observable or we haven't incorporated them yet. However, this leads to the fact, that the assigned counsel penalty also accounts for these characteristics.   
Therefore, let's add another variable and see what happens. How about `male`? 

---

#! addon__quiz__adding male

---

Let's validate the right answers from the quiz.

**Task:**
Compute the correlation between `male` and `hadbondsman` first. Then do the same for the variables `male` and `appointed`. Finally, compute the correlation between `male` and `guilty`.

```{r "2_1__8"}
# Firstly, compute the correlation between male and hadbondsman

# Secondly, compute the correlation between male and appointed

# Finally, compute the correlation between male and guilty
```

Now, let's see what happens, if we add `male` as additional regressor to `appointed` and `hadbondsman`.

**Task:**
Use `lm()` again to run a regression with `guilty` as dependent and `appointed`, `hadbondsman` and `male` as independent variables. Save the regression in a variable `lm.5` and show the result with `summary()`.

```{r "2_1__9"}
# Run the regression first
lm.5 <- lm(formula = ___, data = dat)

# Now, produce the output
summary(lm.5)
```

As you can see, adding `male` again changed all coefficients. However, this time the assigned counsel penalty didn't declined further but increased by 1 percentage point again. Why? Since `male` is negatively correlated with `appointed`, as we have seen before, and positively with `guilty`, adding it to the model accounts for this correlation. So, after we controlled for `male` and `hadbondsman` the left-over variation in `appointed` comes either from random noise or from additional case characteristics, that are correlated with `appointed` and have an effect on `guilty`. Note, that there is also a correlation between `hadbondsman` and `male`, which also has an effect on the assigned counsel penalty. However, we won't discuss this effect in detail here and therefore omit it from the flowchart. Again, you can have a look at this flowchart, that summarizes the links. Again, the dashed line between `appointed` and `male` represents only a correlation, while the solid lines can be interpreted as causal relationships. Being a male defendant lowers the probability of a positive case outcome. So, if we control for it in our regression, the inverse relationship between `appointed` and beneficial case characteristics becomes stronger, which leads to a increase in assigned counsel penalty again.  

<br>

<center>

![Correlations between Case Characteristics, Appointed and Guilty](flowchart2.png)

</center>
*Source: Own creation.*
<br>

Of course, we could and should add further variables to our model in order to account for case characteristics. However, we will see, that sequential addition of covariates is problematic in exercise 3.1 and hence doesn't really help to assess the effect of individual case characteristics on `appointed`. Therefore, we will investigate the full set of case characteristic variables in the next exercise along with adverse selection. What you should have realized in this exercise is that `appointed` is sensitive to other variables, that can help us to account for case characteristics and adverse selection.


## Exercise 2.2 -- Assigned Counsel Penalty

First, let's read in the data again, we will need it.

**Task:** The code is already supplied, just press `check`. 
```{r "2_2"}
dat <- readRDS("Lawyers.rds")
```

In this exercise we will determine the assigned counsel penalty conditional on both, case characteristics and adverse selection. We already examined the unconditional assigned counsel penalty in exercise 2.1 and introduced some covariates, that could potentially help in explaining some of the unconditional penalty. We will now use the full set of regressors proposed by the authors. Again, we will conduct our analysis based on the outcome variable `guilty` and provide the results for other outcomes subsequently. 

Based on the paper, the model we want to estimate is 

$$\begin{alignat}{3}
  y_{ikt}&=\delta + \beta_1assigned_{ik}+X_{it}\Omega+A_{ikt}\Pi+\epsilon_{ikt}, \qquad \text{(2)} \\\
  where \quad X_{it}&=[D_i, o_i, c_{it}] \quad and \quad A_{ikt}=[a_{ik}, \gamma_{kt}]. 
\end{alignat}$$

Hereby, we can estimate $\beta_1$ which is the assigned counsel penalty and $y_{ikt}$ being the response variable. The matrixes $X_{it}$ and $A_{ikt}$ comprise case characteristics and attorney characteristics. We can further subdivide the case characteristics into defendant characteristics $D_{it}$ and the other case characteristics $o_i$ and $c_{it}$. $D_{it}$ contains some of the already familiar defendant variables `male`, `hisp`, `white`, `age_offense`, `povrate`, `instability`, `hadbondsman`, `complaint_hist` and `convict_hist`.   
Case characteristics $o_i$ and $c_{it}$ are captured by the two categorical variables `offense_num` and `court_docket`. With `offense_num` we capture one of 659 offense codes, which distinctly describe the offense. Originally, the offense codes are 8 digits long, where the first four digits depict the NCIC Classification (not important here) and the last four digits represent the Texas specific identifier of the offense. If you have a look at our data, you will see, that we only have four digit offense codes. This is, because our data only provides the Texas specific identifier. For instance, the code "1084" represents interfering with public duties. You can have a look at [Texas Department of Public Safety](https://www.dps.texas.gov/administration/crime_records/pages/appndxkoffensecodes.htm) for additional information.    
The variable `court_docket` is a unique combination of court and charge year. Because in Bexar County each court has one judge, this variable aims to control for the judge the defendant faced.   
The matrix $A_{ikt}$ can also be subdivided into $a_{ik}$, which includes directly observable and measurable attributes of attorneys and the match with their defendants, and $\gamma_{kt}$. Attorney characteristics in $a_{ik}$ are given by the variables, `atty_exp`, `pct_appt`, `distance_to_atty`, `racematch` and `caseload_retained`. What we haven't looked at so far is $\gamma_{kt}$, which contains **attorney-by-year fixed effects**. But before we are going to discuss what we mean by fixed effects, let's first turn our attention to the subscripts in equation (2).

We have three subscripts $i$, $k$ and $t$. The subscript $k$ represents an attorney, while $i$ constitutes a case and $t$ describes the year. To depict the year, we use the time variable `complaintyear` and to identify each distinct attorney we use `attybarcard`. As we already examined before, there are 726 attorneys over the time period 2005-2014 with a total amount of 64209 cases. Hence, we observe each attorney $k$ in $T_i$ time periods, whereby we observe a number of cases in a time period $t$ for each attorney $k$. If you click at the `data` above a code chunk you will recognize this structure. The first column lists attorneys $k$ based on `attybarcard`, the second column lists $t$ based on `complaintyear` and columns three and four are listing our main outcome variable `guilty` and the treatment variable `appointed`.  

As a last step, before running the model, let's discuss attorney-by-year fixed effects $\gamma_{kt}$. This are dummy variables for every attorney-year combination, that we include into our model. We do so, because we want to account for **unobserved heterogeneity**. That means, that there is variation in variables, that could help us to assess the effect of `appointed` on `guilty`, but we can't observe these variables (we don't have them in our data). Including attorney-by-year fixed effects solves this problem, because it accounts for any unobserved variation in attorneys across years. In this specification, the assigned counsel penalty is identified off variation within attorneys who work as both assigned and retained counsel in the same year. To get a better grasp about the various dummies of attorney-by-year fixed effects, let's compute how many are present and the number of cases in each group. 

**Task:**
Let's use `dplyr` again. First `group_by()` `attybarcard` and `complaintyear`. 
Afterwards, use `summarize()` and assign the function `n()` to a new variable `ay_cases`.
Additionally, compute the mean and standard deviation for every attorney-year combination.
Finally, save the results into `ay_grouped` and show the results.

```{r "2_2__2"}
# I already provided some code
# You have to fill in the middle part, where ___ is located
ay_grouped <- dat %>% 
  ___ %>% 
  summarize(ay_cases=n(),
# now compute assignment rate
  ay_mean=mean(appointed),
# calculating se for further insight
  ay_se=var(appointed)^0.5)
# Show output
nrow(ay_grouped)
ay_grouped
summary(ay_grouped)
```

As you have ascertained, there are a total of 4421 attorney-year combinations with 15 cases per year on average. 
Now let's do the same thing, but filter out all attorneys, who worked just as assigned or retained in a year.

**Task:**
We add the `filter()` function and apply it to `ay_grouped` in order to remove all unsuitable groups. 
Note that we defined `ay_group` in the previous task.
The argument of `filter()` is a logical expression based on the assignment rate in each group and filters all
attorney-year combinations without variation. 
The solution is already provided, just press `check`.

```{r "2_2__3"}
# We start, like in the previous task
ay_grouped_filtered <- ay_grouped %>% 
  # Now we filter out all unsuitable groups
  filter(ay_mean < 1 & ay_mean > 0)
# Show outputs again
nrow(ay_grouped_filtered)
ay_grouped_filtered
summary(ay_grouped_filtered[,3:5])
```

Firstly, note that we are left only with 2186 groups of attorney-year combinations. Consequently, we lose 2235 combinations of attorney-year. Secondly, in the leftover attorney-years the number of handled cases is on average 20, which is far higher, than the 15 cases from the full data. There is a multitude of possible reasons for this difference. But one possible explanation might be, that we filtered out mostly attorneys, who only work on the private market, where they don't have to take on so many cases, because they are paid much better. 

**Task:** 
Find out, how many of the filtered-out attorney-year combinations belong to retained cases.
Again, use `summary()` to compute the mean cases across the filtered attorney-year combinations.
Solution is provided just press `check`.

```{r "2_2__4"}
# Changing the argument of filter appropriately
ay_grouped %>% filter(ay_mean == 1) %>% nrow(.)
# Print summary
summary(ay_grouped %>% filter(ay_mean == 1))
```

Indeed, roughly 60% of the attorney-year combinations, which we filtered out are working on the private market exclusively and they take on approximately 9.5 cases on average, which is less compared to the full set of attorney-year combinations. By the way, the average number of cases handled for the filtered-out attorney-year combinations of only assigned cases amounts to roughly 7.5. It follows, that attorneys who work as both, assigned and retained, take on far more cases, than the other two groups. 

Now let's finally run the model stated in equation (2) in order to calculate the assigned counsel penalty $\beta_1$. We use will use the `felm()` function from the `lfe` package to achieve this task. The `felm()` function works similarly to the `lm()` function. However, the difference is, that `felm()` has a more elaborate way to deal with the fixed effects, which is must faster than the dummy variable approach internallty used by the `lm()` function. The syntax of the `formula` consists of four parts: The first part contains the ordinary covariates, the second part encompasses the fixed effects to be projected out, the third part allows for instrumental  variables and the last part adds the option to specify clustered standard errors. Please inspect the help page, for an example of the `formula` syntax and for further information, particular about additional arguments. The `lfe` package was developed by *Gaure* (2013a, 2013b). You can have a look at his papers for some clarification of fixed effects estimation with `lfe`. 

**Task:** 
Run the full model as specified in equation (2) using `felm()` and save it in a variable called `fe.model`. 
Afterwards eject the output with `summary()`. 
The code is already provided, just press `check`.

```{r "2_2__5"}
# Run the model and print the results
fe.model <- felm(guilty ~ appointed + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + 
              white + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + racematch + 
              caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, 
              cmethod="reghdfe", data=dat)
summary(fe.model)
```

The result shows that the assigned counsel penalty yields 8.5% after we account for case and attorney characteristics. Remember, that we had determined an unconditional assigned counsel penalty of 18.3%. This means, case and attorney characteristics jointly explain 9.8 percentage points in disparity. Note, however, that we can't assess the individual effect of attorney characteristics and case characteristics yet, because both effects are intertwined, but we will do so in the next exercise.

#! start_note "clustered standard errors"
As you can see in the call to `felm()`, we speficied in the fourth part of the `formula` syntax, that we want to cluster the standard errors by `attybarcard`, viz. on the attorney level. This info box will explain to you, what this actually means.
You probably know, how to derive the formula for standard errors in OLS. If not, have a look at the bottom info box. Additionally to the assumption of independent distributed error terms $\epsilon$, the paramount assumption underlying the sampling variance in fixed effects models is $Var(\epsilon_{ikt}|Z_{ikt}, \gamma_{kt})=\sigma^2$. Note, that we denote $Z_{ikt}$ as the vector containing the full set of regressors from equation (2).
Sadly, we can't assume this to hold true generally. Firstly, there could be heteroscedasticity. In that case we necessitate *White* (1980) standard errors. Secondly, there could be autocorrelated error terms among cases or serial correlation across time leading to wrong standard errors we must account for, as *Newey, Kenneth, West* (1987) point out. However, we want to allow the disturbance term to be correlated within clusters, but to fulfill the iid assumption between clusters. The typical example of clusters are schools, where students are nested within classrooms. Because all students have for example the same teacher, we can't expect test results being independent.   
In our case we will define clusters on the attorney level. That is, we allow for correlation in the disturbance terms among cases and across years within each attorney but expect no correlation between attorneys. In this case we can state the variance-covariance matrix of the coefficients as
$$\begin{align}
  Var(\hat\beta)=(Z^TZ)^{-1}\left(\sum_{k=1}^KZ_k^T\Sigma_kZ_k\right)(Z^TZ)^{-1}, \qquad \text{(3)}
\end{align}$$

where $Z$ is the matrix over all regressors and observations and $Z_k$ is the matrix over all regressors and observations within an attorney $k$. The variance-covariance matrix of within attorney error terms is denoted as $\Sigma_k=Var(\epsilon_k|Z_k)=\mathbb{E}[\epsilon_k\epsilon_k^|Z_k]$.   
Note that under homoskedasticity this simplifies to our well-known OLS coefficient variance. Also, you should be aware of the fact, that clustering only is applicable, if we have a high number of clusters. We already examined, that our dataset contains 726 attorneys, so we can put our mind at rest, at least in this respect. One final remark, while the effect of heteroscedasticity on our estimates often is bearable, not accounting for clustered standard errors might greatly harm significance of our results, as *Angrist, Pischke* (2008) showcase in chapter 8 of their book. More precise, *Moulton* (1986, 1990) points out, that in this case our standard errors are seriously downward biased.  
There is an extensive literature out there, on how to estimate $\Sigma_k$. I won't illustrate all the details here, but you should know, that the `felm()` function works based on *Cameron, Gelbach, Miller* (2008, 2012). Moreover, *Correia* (2015) discusses the problems, that arise, when fixed effects are nested within clusters, as in our case where attorney-by-year fixed effects and attorney clusters interfere. Furthermore, you can explore *White* (1984), *Liang, Zeger* (1986) and  *Arellano* (1987) in order to study the fundamentals of cluster robust inference or take a look at *Cameron, Miller* (2015) for a more hands-on approach. By the way, the two arguments `cmethode` and `exactDOF` help us to align the estimator produced by `felm()` and its companion function `reghdfe` from Stata, which is the statistical language the authors used to produce their results. 

info("Standard Error in OLS") # Run this line (Strg-Enter) to show info

#! end_note

Finally, let's contemplate the other outcome variables, we have put aside until now. Everything we discussed so far applies just as well for these other variables. We will take a look at `dismissed`, `defadj`, `incarcerated`, `reduced`, `lnsent` and `lnfine`.

**Task:**
The code is already provided, just press `Check`. Note, that computations can take a moment. 
Afterwards, go on to the next task in order to produce the output. 
Note that `felm.form()` is my own user defined function. It simply puts together the various parts of the `felm()` `formula` syntax. 

```{r "2_2__6"}
# List all outcome variables
depvar <- c("dismissed", "defadj", "incarcerated", "reduced", "lnsent", "lnfine")
regress <- c("appointed male age_offense complaint_hist convict_hist hadbondsman hisp white povrate instability lndist atty_exp pct_appt racematch caseload_retained")
fixed.eff <- c("atty_year offense_num court_docket")

# Use lapply() to loop through depvar in order to run one regression for each outcome
# the results get stored in a nested list structure in model_all
model_all <- lapply(depvar, function(x) {
  felm(felm.form(dep.var = x, 
                 ind.vars = regress, 
                 feffects = fixed.eff,
                 iv = F,
                 endogen = NULL,
                 instruments = NULL,
                 cluster = "attybarcard"), 
       data = dat, cmethod = "reghdfe", exactDOF = T)
}
)

# Assign appropriate names to list elements
names(model_all) <- depvar

# Prepare Output
regressor.labels <- c("Assigned Counsel Penalty", "Male Defendant", "Age at Offense", 
                      "Previous Complaints", "Previous Convictions", "Detained Pre-Adjudication", "Hispanic", "White",
                      "Home Poverty Rate", "Local Borrowing Costs", "Distance from Home to Law Office", "Previous Cases", 
                      "Percent of Cases Assigned", "Ethnic Match", "Average Retained Caseload")

output.label <- c("Dismissed", "Def. Adj.", "Incarcerated", "Reduced Charge", "Log Sent", "Log Fine")

```


**Task:**
Use the command `stargazer()` from the identically named package to show the regression output for `model_all`. Some arguments are already provided, you just need to fill in the model name `model_all`. 
Note that, the computation can again take a moment. 

```{r "2_2__7",results='asis'}
# Produce Regression Table
stargazer(___, type ="html", title="Assigned Counsel Penalties for different Case Outcomes", out.header = T, covariate.labels = regressor.labels,  column.labels = output.label, dep.var.labels = "", model.names = T, digits=5)
```


---


#! addon__quiz__regression output

---

#! addon__quiz__regression output2

<br>

info("log-level specification") # Run this line (Strg-Enter) to show info

---

#! addon__quiz__regression output t value

---


Lastly for this exercise, note that for a variable like `incarcerated` it would be insightful if we could come to know the assigned counsel penalty under the conditional assumption of being convicted before. The reason to do so is obvious, without conviction there can't be an incarceration (although we have 26 such occurrence in our data for some reason). The same logic applies to `lnsent` and `lnfine` (where there are indeed no sentences or fines without conviction). Fortunately, accomplishing this task is very straight forward. 

**Task:**
Use `felm()` again to run a set of models on a number of outcome variables defined in `depvar_cond`. 
Use the `subset` argument of the `felm()` function in order to condition only on cases, where the defendant has be found guilty.
Finally, produce the outputs again with `stargazer()`. The code is already complete.

```{r "2_2__8",results='asis'}

# Define new set of dependent variables
depvar_cond <- c("incarcerated", "lnsent", "lnfine")

# This two are the same as in the last task
regress <- c("appointed male age_offense complaint_hist convict_hist hadbondsman hisp white povrate instability lndist atty_exp pct_appt racematch caseload_retained")
fixed.eff <- c("atty_year offense_num court_docket")

# Use lapply() to loop through depvar in order to run one regression for each outcome
# remember to specify the subset argument in order to condition of conviction cases only
# the results get stored in a nested list structure in model_all
model_cond <- lapply(depvar_cond, function(x) {
  felm(felm.form(dep.var = x, 
                 ind.vars = regress, 
                 feffects = fixed.eff,
                 iv = F,
                 endogen = NULL,
                 instruments = NULL,
                 cluster = "attybarcard"), 
       data = dat, cmethod = "reghdfe", exactDOF = T, subset=(guilty==1))
}
)

# Assign appropriate names to list elements
names(model_cond) <- depvar_cond

# Prepare Output
regressor.labels <- c("Assigned Counsel Penalty", "Male Defendant", "Age at Offense", 
                      "Previous Complaints", "Previous Convictions", "Detained Pre-Adjudication", "Hispanic", "White",
                      "Home Poverty Rate", "Local Borrowing Costs", "Distance from Home to Law Office", "Previous Cases", 
                      "Percent of Cases Assigned", "Ethnic Match", "Average Retained Caseload")

output.label <- c("Incar. | Convic.", "Log Sent | Convic.", "Log Fine | Convic.")

# Produce Output
stargazer(model_cond, type ="html", title="Assigned Counsel Penalties for different Case Outcomes conditional on Conviction", out.header = T, covariate.labels = regressor.labels,  column.labels = output.label, dep.var.labels = "", model.names = T, digits=5)

```


## Exercise 3 -- Decomposition of Assigned Counsel Penalty

The main contribution of the authors to the field of criminal justice research is the assessment, how the assigned counsel penalty can be attributed to case characteristics, adverse selection, matching and moral hazard. This is possible through the unique data, that we have at hand, where we can observe the same attorney across cases taken on in the same year. As a result, we can partial out case and attorney characteristics. Hereby, we can draw two conclusions: Firstly, the difference in conditional and unconditional assigned counsel penalty is attributed to observed case characteristics and adverse selection. Secondly, the residual assigned counsel penalty (remaining difference in outcomes, when attorney is assigned vs. retained) must be due to moral hazard and matching preferences between attorney and client. 

In this section you will learn, how we can decompose the difference between the conditional and unconditional assigned counsel penalty in exercise 3.1. Afterwards, we will thoroughly examine matching preferences and moral hazard, which are two possible explanations for the residual assigned counsel penalty.

## Exercise 3.1 -- Case Characteristics and Adverse Selection


For this exercise it is required to reshape our data. Because I already performed the transformation in order to save us some time, you just need to load the new data set. You can find a short description of the new data below the chunk, as well as additional information on the transformation process in the corresponding info box. 

**Task:**
Read in the data by clicking `check`.

```{r "3_1"}
dat <- readRDS("Lawyers_dummy.rds")
```

This data reshapes the `factor` variables `atty_year`, `offense_num` and `court_docket` into dummy variables, where each factor level corresponds to one dummy. This yields additional 5185 dummy variables. I already performed the transformation. Because neither `atty_year` nor `offense_num` or `court_docket` were consecutive sequences of numbers I changed them to be so. Offense codes display the prefix *oc*, court dockets use *cd* and attorney-year combinations are denoted by *ay*. 

info("Adding Dummy Variables to our Data") # Run this line (Strg-Enter) to show info

In this chapter we will decompose the difference between the unconditional assigned counsel penalty and the conditional assigned counsel penalty. Before we do so on the full set of regressors, as specified in equation (2), let's consider an easier specification in the form of 

$$\begin{align}
  guilty = \beta_0 + \beta_1assigned + \beta_2complaint\_hist+\beta_3hadbondsman+\xi. \qquad \text{(4)}
\end{align}$$
Note, that we dropped the subscripts in this equation. We do this, because equation (4) just serves as illustration for decomposition and we already now, that we can estimate it with OLS over all observations/cases $i$. The regressor $hadbondsman$ is an indicator variable, which is 1, if a bail was posted and 0 else. 
Let's assume for a moment, that equation (4) represents the true model. In this case, one interesting question, that arises is: What is our prediction of the consideration of `complain_hist` and `hadbondsman` on $\beta_1$. A naive approach to assess this question might be to sequentially add both variables to the base specification as we did in exercise 2.1. 

**Task:**
In this task we will compute all regressions in order to examine, how sequential addition affects $\hat\beta_1$.    
1. Use `lm()` to estimate the base model.     
2. Compute a second regression, where you add `complain_hist` to the base specification.    
3. Compute a third model, with `hadbondsman` as addition to base, but without `complain_hist`.    
4. Finally run the full model, as in equation (4).    
5. State all results with the help of `stargazer()`.    
Note, that step one, four and five are already provided in the code. You just have to correctly specify the `formula` of the `lm()` command in step two and three. 

```{r "3_1__3",results='asis'}

# Run base specification
naive_base <- lm(guilty~appointed, data=dat)

# add complaint history
add1 <- lm(formula=___, data=dat)

# add hadbondsman variable
add2 <- lm(formula=___, data=dat)

# Run full specification
naive_full <- lm(guilty~appointed+complaint_hist+hadbondsman, data=dat)

stargazer(naive_base,add1,add2,naive_full, type="html", digits=5)

```


Answer this quiz questions, that will guide you through the computational steps of sequential decomposition. Note, that we are only interested in $\hat\beta_1$ and therefore you only have to look at the first row. Keep attention on the sign. Because $\hat\beta_1$ is decreasing in each step, compared to the base specification you need to include a negative sign in your answers. Because `guitly` is a dummy variable with values zero and one, let's interpret the numbers as percentage points. Therefore, multiply your results by 100 before answering, e.g. you would state the difference between 0.364 and 0.291 as -7.3. 

---

#! addon__quiz__Sequential Decomposition

<br>

---

This table summarizes your calculations. The first column states the effect sizes, when first adding the complaint history and the second column represents the opposite of first adding `hadbondsman`. 

<br>

<table style="margin-left:auto;margin-right:auto;">
<caption style="font-size: initial !important; text-align:center;">The effect of sequential addition on assigned counsel penalty</caption>
 <thead class="slider-thead">
  <tr>
   <th class="swiper-th">   </th>
   <th class="swiper-th"> CH then Bail </th>
   <th class="swiper-th"> Bail then CH </th>
  </tr>
 </thead>
<tbody class="slider-tbody">
  <tr>
   <td class="slider-td"> Complaint History </td>
   <td class="slider-td"> -2.8 </td>
   <td class="slider-td"> -0.7 </td>
  </tr>
  <tr style="background-color: #f3f3f3;">
   <td class="slider-td"> Bail </td>
   <td class="slider-td"> -8.5 </td>
   <td class="slider-td"> -10.6 </td>
  </tr>
  <tr>
   <td class="slider-td"> Total </td>
   <td class="slider-td"> -11.3 </td>
   <td class="slider-td"> -11.3 </td>
  </tr>
</tbody>
</table>

<br>

---

As you see, if we first control for complaint history the assigned counsel penalty decreases by 2.8 percentage points. However, if we first consider `hadbondsman`, the variation in complaint history _increases_ the outcome gap between assigned and retained attorneys by 0.7 percentage points. Note, that saying, variation in complaint history increases $\hat{\beta_1}$ by 0.7 percentage points is equivalent to state, controlling for complaint history (additional to `hadbondsman`) reduces $\hat{\beta_1}$ by 0.7 percentage points. 
Maybe you can already imagine what the point is, that I want to make. How does it come, that there are two different effect sizes for the same variable? Is the complaint history reducing the assigned counsel penalty by 2.8 percentage points or just by 0.7? What we stumble upon here, is **sequence-sensitivity of the sequential addition**. That means, it makes a difference in which order we add the covariates. But why is that and can we come up with another decomposition to get the insights about what is driving the difference $\hat{\beta_1}^{base}-\hat{\beta_1}^{full}$? 

For the first part of the question - the reason is, that the regressors are not independent, but correlated. To see this let's run some auxiliary regressions. 

**Task:**
Run for both added variables `complaint_hist` and `hadbondsman` two regressions. Regress them on `appointed` in the first one and then add the other as explanatory variable in the second.  
The code is already supplied for the first variable, you have to fill in the analogous code for the second variable.

```{r "3_1__4",results='asis'}

# Auxiliary regressions for complaint history
aux1 <- lm(complaint_hist ~ appointed, data=dat)
aux1c <- lm(complaint_hist ~ appointed + hadbondsman, data = dat)

# Now do the same for the bail variable
aux2 <-  lm(formula = ___, data = dat)
aux2c <- lm(formula = ___, data = dat)

# Finally, we retrieve the results
stargazer(aux1, aux1c, aux2, aux2c, type="html", digits=3)
```

---

Look how the relationship between `appointed` and `complaint_hist` changes before and after we include `hadbondsman`. On average, the defendants of 1000 assigned counsels got 447 more charges in the past than the defendants of 1000 retained counsels. If we include the bail variable this difference shrinks to 136. You can draw a similar conclusion for the bail variable. That is, if we add a variable, we can't attribute the whole difference to the treatment variable in question (in our case the assignment dummy) but need to account for the present correlations among sets of explanatory variables. 

After we explained, why we can't use sequential addition to decompose the difference between the base and full model, let's now turn our attention on another decomposition method, that doesn't suffer from the serious drawbacks, which we just discussed. The decomposition method we will us, was proposed by *Gelbach* (2016). He uses the omitted variables formula to assess the gap between $\beta_1^{base}$ and $\beta_1^{full}$, which we state as

$$\begin{alignat}{3}
  \hat{\beta_1}^{base} &= \hat{\beta_1}^{full}+(X_1^TX_1)^{-1}X_1^TX_2\hat{\beta_2} \\\
  \Leftrightarrow \qquad \hat\delta \equiv \hat{\beta_1}^{base}-\hat{\beta_1}^{full} &= (X_1^TX_1)^{-1}X_1^TX_2\hat{\beta_2}, \qquad \qquad \text{(5)}
\end{alignat}$$
for a model $y=X_1\beta_1+X_2\beta_2+\phi$.
Further, if $X_{2k}$ is the k-th column of observations in $X_2$, we can write
$$\begin{align}
  \hat\Gamma_k= (X_1^TX_1)^{-1}X_1^TX_{2k}, \qquad \text{(6)}
\end{align}$$
as the OLS estimated coefficient on $X_1$ from an auxiliary model with $X_{2k}$ as the dependent variable. For instance, if we examine a linear model as in equation (4), we can restate equation (6) (for $k=1,2$) as
$$\begin{alignat}{3}
  \hat\Gamma_1 &= (assigned^T*assigned)^{-1}*assigned^T*complaint\_hist, \\\
  \hat\Gamma_2 &= (assigned^T*assigned)^{-1}*assigned^T*hadbondsman. \qquad \text{(7)}
\end{alignat}$$

Because the omitted variables bias formula is linear, we can write equation (5) as
$$\begin{align}
  \hat\delta = \sum_{k=1}^{k_2}\hat\Gamma_k\hat\beta_{2k}=\sum_{k=1}^{k_2}\hat\delta_k, \qquad with \quad \hat\delta_k=\hat\Gamma_k\hat\beta_{2k}. \qquad \text{(8)}
\end{align}$$
Note, that $\hat\beta_{2k}$ is the estimated coefficient on $X_{2k}$ in the full model specification and $k_2$ is the number of columns in $X_2$. 

That is, all we have to do in order to decompose the difference between the conditional and unconditional assigned counsel penalty is to apply equation (7). Let's do that first for our small model (equation (4)) with `complaint_hist` and `hadbondsman` as the only two variables in $X_2$. Afterwards, we will follow the same procedure to get a decomposition of our truly full specified model, as it is stated in equation (2). 

Because we already computed everything that is essential to apply the decomposition for the small model, we can straightaway do the computation. 

**Task:**
The code is already provided, just press `check`. 

```{r "3_1__5"}

# Compute effect sizes
effect_ch <- coef(aux1)[2]*coef(naive_full)[3]
effect_bail <- coef(aux2)[2]*coef(naive_full)[4]

# Compute total difference between base and full
delta <- effect_ch + effect_bail

# Compute effect sizes as shares
effect_ch_share <- effect_ch/delta
effect_bail_share <- effect_bail/delta

# Print results
list(delta.sum=delta, delta.mat=c(effect_ch, effect_bail), delta.share=c(effect_ch_share, effect_bail_share))
```

Note, how both effects add up to the total difference $\hat\delta=-11.3$ (in percentage points) between the base and full regression from equation (4). Also, notice that the effect sizes differ in comparison to the ones obtained by sequential addition (stated in the above table). We just acquired all knowledge in order to decompose the main model. But before we do so, let's first rerun the models from equation (1) and (2) in order to restate the difference in unconditional and conditional assigned counsel penalty $\hat{\beta_1}^{base}-\hat{\beta_1}^{full}$. 

**Task:**
The code for the full model is already provided. However, you need to fill in the arguments of the `lm()` function to run the base model. You can revisit exercise 2.1 in order to recall the base specification.

```{r "3_1__6",results='asis'}
# Fill in the formula and data arguments to run the base specification
fe.base <- felm(formula=___, data=dat)

# Now run the full regression
fe.full <- felm(guilty ~ appointed + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + 
              white + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + racematch + 
              caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, 
              cmethod="reghdfe", data=dat)

# Finally, print the output
stargazer(fe.base, fe.full, type ="html", title="Unconditional and Conditional Assigned Counsel Penalties on Conviction", out.header = T, dep.var.labels = "", model.names = T, digits=3, keep="appointed")

```

<br>

---

#! addon__quiz__total assigned counsel penalty

<br>

---


However, there is a little downside on the computational side. In order to do the calculation, we need to run many, many regressions. It would be very cumbersome and inefficient to do that by hand. So let's make a virtue out of necessity and learn how to write a function in order to automate the computation. 

We will write the function step-by-step. At first, we should always think about the input required and computed output of a function. The output should look like the one, we computed for the small model (equation (4)). For the input we need arguments for $X_1$ and $X_2$ from the model underlying equation (5). Let's denote them as `x1.vars` and `x2.vars`. We also require arguments specifying the outcome variable and the data. We choose `y.var` and obviously `data`. Finally, if we compute so many effects, we are rarely interested in each and every one. Hence, we necessitate an argument, which accounts for grouping explanatory variables in $X_2$. Let's call it `x2.grouped`.    
We have talked so far about the arguments. A user-defined function however consists of a name, the arguments and finally the body. Let's therefore call our function `gelbach.decomposition()`. Before we go on, let's have a look at what we have so far: 

info("preknit_XFvGgIBMdGAx") # Run this line (Strg-Enter) to show info


Prior to writing the body, let's already define the arguments, which we want to commit to the function.
We begin by combining the generated dummy variable names based on `offense_num`, `court_docket` and `atty_year`. 

**Task:**
We use the `matches()` function from `tidyselect` in order to select the relevant names.
The code is already provided, just press `check`.

```{r "3_1__8"}
ay_names <- names(dat)[matches("^ay", ignore.case = F, vars = names(dat))]
oc_names <- names(dat)[matches("^oc", ignore.case = F, vars = names(dat))]
cd_names <- names(dat)[matches("^cd", ignore.case = F, vars = names(dat))]
```

Continue with defining an variable for the `x2.grouped` argument. We want to have two groups. We summarize all names of case characteristics, as denoted in equation (2) by $X_{it}$, in one group and all attorney characteristics, as denoted by $A_{ikt}$, in the other group. 

**Task:**
Define a variable of `class()` `list`, where we rearrange the explanatory variables into groups.
Again, you just need to click on `check`.

```{r "3_1__9"}
group_vars=list(client=c("male", "age_offense", "povrate", "instability", "complaint_hist", "convict_hist", "hadbondsman",
                        "hisp", "white", cd_names, oc_names), 
                atty=c("lndist", "atty_exp", "pct_appt", "racematch", "caseload_retained", ay_names))
```

Now we can define the input arguments.


**Task:**
Specify the arguments, which we deliver to our function `gelbach.decomposition()`. 
The code is already provided.

```{r "3_1__10"}

data=dat
y.var="guilty"
x1.vars="appointed"
x2.vars=c("male", "age_offense", "povrate", "instability", "complaint_hist", "convict_hist", "hadbondsman", 
"hisp", "white", cd_names, oc_names, "lndist", "atty_exp", "pct_appt", "racematch", "caseload_retained", ay_names)
x2.grouped=group_vars
```

With the exact knowledge on how our input variables look like, let's now write the body of the function. 
We will do so in multiple steps and afterwards put the function together.

**Task - Step 1:**
Start simply by extracting the outcome variable `y.var` from the `data`.
Also state the number of elements in the vectors of names `x1.vars` and `x2.vars`.

info("preknit_DOdavhKJqrUt") # Run this line (Strg-Enter) to show info

**Task - Step 2:**
Add the explanatory variables of interest in `x1.vars` and the controls in `x2.vars` into a single design matrix in order to run the full regression afterwards. Save the coefficients from the full regression in a variable `coef.full`. Finally, extract all coefficients of the variables in `x2.vars`. 

info("preknit_nJfCocbaiLQW") # Run this line (Strg-Enter) to show info

**Task - Step 3:**
For the purpose of running the auxiliary regressions - create the design matrix which is based on `x1.vars` purely. 
Also initialize a matrix `delta.mat` to store the effects $\hat\delta_k$ (see equation (6)). 
Now run the auxiliary regressions and compute $\hat\delta_k$. Save the results in `delta.mat`.
Finally compute the total gap between the base and full model $\hat\delta$ by summing over all $\hat\delta_k$ and calculate the percentage effect. 

info("preknit_fxNrXBUNDOTn") # Run this line (Strg-Enter) to show info

**Task - Step 4:**
In this step we will take care of the grouping. We start by checking, if the grouping variable `x2.grouped` is specified. If not, output the results `delta.sum`, `delta.mat` and `delta.share` from the last step in a list element. If `x2.grouped` is specified, calculate the group effects `delta.grouped` for each variable in `x1.vars` by summing over the respective $\hat\delta_k$ in `delta.mat`. Output a list as in step 3, but with `delta.grouped` instead of `delta.mat`. 

info("preknit_GNiiVPOQvPTp") # Run this line (Strg-Enter) to show info

**Task - Step 5:**
Now add all together in our function `gelbach.decomposition()`. Press `check`.

```{r "3_1__15"}
gelbach.decompositon = function(data, y.var, x1.vars, x2.vars, x2.grouped=NULL) {

# Step 1
y = data[[y.var]]
n1 = length(x1.vars)
n2 = length(x2.vars)

# Step 2
X.full = cbind(1,as.matrix(data[,c(x1.vars,x2.vars)]))
coef.full = coef(lm.fit(y=y,x=X.full))
beta2 = coef.full[(n1+2):(length(coef.full))]

# Step 3
X1 = cbind(1,as.matrix(data[,c(x1.vars)]))
delta.mat = matrix(0, n1,n2)
rownames(delta.mat) = x1.vars
colnames(delta.mat) = x2.vars
x2.ind = 1
for (x2.ind in seq_along(x2.vars)) {
  gamma = coef(lm.fit(y=data[[x2.vars[x2.ind]]],x=X1))[-1]
  delta.mat[,x2.ind] = gamma * beta2[x2.ind]
}
delta.sum = rowSums(delta.mat)
delta.share = delta.mat / delta.sum

# Step 4
if(!is.null(x2.grouped) & is.list(x2.grouped)) {
  
  group_num <-  length(x2.grouped)
  group_names <- names(x2.grouped)
  delta.grouped = NULL
  
  
  for (i in 1:n1) {
    delta.row <- NULL
  
  for (g in 1:group_num) {
    group <- paste0("group", g)
    assign(group, sum(delta.mat[i,x2.grouped[[g]]]))
    delta.row <- cbind(delta.row, eval(parse(text=group)))
  }
  
  delta.grouped <- rbind(delta.grouped, delta.row)  
  colnames(delta.grouped) <-  group_names
  
  }
  
  rownames(delta.grouped) <-  x1.vars
  delta.share = delta.grouped/delta.sum
  list(delta.sum=delta.sum, delta.grouped=delta.grouped, delta.share=delta.share)

} else {

  list(delta.sum=delta.sum, delta.mat=delta.mat, delta.share=delta.share)

  }
}
```


After we defined the function let's first reassure ourselves, that we did everything correct. So before running the model with full specifications, let's test the function on the simple model in equation (4). 

**Task:**
Use `gelbach.decomposition()` to decompose the model in equation (4).

```{r "3_1__16"}

gelbach.decompositon(data=dat,
                     y.var = "guilty",
                     x1.vars= "appointed",
                     x2.vars = c("complaint_hist", "hadbondsman"),
                     x2.grouped = NULL)

```

It looks like everything is working fine, since we get the same results, as the one we calculated manually. 
So let's apply our decomposition function on the full model, stated in equation (2).

**Task:**
Use the newly defined function `gelbach.decomposition()` to decompose the model stated in (2) in relation to the base model with `appointed` being the only explanatory variable. 
Remember, that we already assigned all variables to the argument names. 
Note, that because the computation takes very long, we just show the code here and will read in the solution to the call to our function in the next task.

info("preknit_pTqQzhedghxE") # Run this line (Strg-Enter) to show info

**Task:**
Use the function `readRDS()` to read in the solution to the above function call and save it in a variable `decomposed`.
Show the results of the above call to `gelbach.decomposition()` saved in `decomposed`.
The code is already supplied, just click on `check`.

```{r "3_1__18"}
decomposed <- readRDS("decomposed.rds")
decomposed
```


As you see, we get the same results as the ones in figure 2 in the authors paper. However, our function isn't that evolved compared to the one, which they used. For example, we didn't calculate clustered standard errors and hence can't report confidence intervals like they do, so it would be definitely well worth taking a look at their table. Because the computation is very time consuming, we won't repeat it for the other outcome variables. Doing so wouldn't be by any means difficult, all we would have to do is changing the `y.var` argument to the name of the outcome variable we want to consider next. Note, that you can take a look at the decomposition of the four main variables analyzed by the authors in the table below. Also, the results are again reported in percentage points with percentage changes in relation to the base specification in parenthesis. 


<br>


<table style="margin-left:auto;margin-right:auto;">
<caption style="font-size: initial !important; text-align:center;">Decomposition Results</caption>
 <thead class="slider-thead">
  <tr>
   <th class="swiper-th">   </th>
   <th class="swiper-th"> Convicted </th>
   <th class="swiper-th"> Dismissed </th>
   <th class="swiper-th"> Def. Adj. </th>
   <th class="swiper-th"> Inc. | Convic. </th>
  </tr>
 </thead>
<tbody class="slider-tbody">
  <tr>
   <td class="slider-td"> Base Specification </td>
   <td class="slider-td">  18.3 </td>
   <td class="slider-td"> -13.5 </td>
   <td class="slider-td"> -5.6 </td>
   <td class="slider-td">  7.5 </td>
  </tr>
  <tr style="background-color: #f3f3f3;">
   <td class="slider-td"> Case Characteristics </td>
   <td class="slider-td"> -6.2 (34%) </td>
   <td class="slider-td">  4.2 (31%) </td>
   <td class="slider-td">  2.0 (36%) </td>
   <td class="slider-td"> -5.8 (77%) </td>
  </tr>
  <tr>
   <td class="slider-td"> Attorney Characteristics </td>
   <td class="slider-td"> -3.6 (20%) </td>
   <td class="slider-td">  3.2 (24%) </td>
   <td class="slider-td">  0.4 (7%) </td>
   <td class="slider-td">  0.6 (8%) </td>
  </tr>
  <tr style="background-color: #f3f3f3;">
   <td class="slider-td"> Full Specification </td>
   <td class="slider-td">  8.5 (46%) </td>
   <td class="slider-td"> -6.1 (45%) </td>
   <td class="slider-td"> -3.2 (57%) </td>
   <td class="slider-td">  2.3 (31%) </td>
  </tr>
</tbody>
</table>


<br>

The table shows, that we can explain between 43 and 55 percent in the assigned counsel penalty differences through case/defendant characteristics and attorney characteristics for the variables `guilty`, `dismissed` and `defadj`. Regarding the incarceration conditional on all cases with a guilty judgement, case/defendant characteristics and attorney characteristics explain together 69% in the gap between the base and full model specification.  
If we take a look at the convictions in the first column, the second and third row reveal that case characteristics explain 34 % of the difference between the base and full specification while adverse selection accounts for 20% of the unconditional assigned counsel penalty. So, there remains a residual assigned counsel penalty of 8.5 percentage points, that we can't explain by observed case characteristics nor attorney characteristics. 
On average, indigent clients are 13.5 percentage points less likely to have their cases dismissed than non-indigent clients. Controlling for client and case characteristics accounts for 31 % of the unconditional assigned counsel penalty. Variation in attorney characteristics is responsible for an 24% increase in the gap between the full and base model. Note, that the authors point out, that even the 95 % confidence interval only yields that 43 % of the unconditional disparity is due to adverse selection.     
The Likelihood to receive deferred adjudication is for clients, that are represented by assigned counsels on average 5.6 percentage points lower. Variation in case characteristics explains 36% of the disparity. Whereas, adverse selection is virtually negligible, accounting only for 7% of the gap. The remaining conditional assigned counsel penalty amounts to 3.2 percentage points or 57%.   
A glance at the last column unveils that the unconditional assigned counsel penalty amounts to 7.5 percentage points in terms of incarceration (conditional on conviction). Most of this disparity can be explained by case characteristics, which account for 77% of the gap in incarceration outcomes. Again adverse selection plays a very minor role in explaining the differences between the base and full specification. Indeed, controlling for attorney characteristics seems to increase the gap by little. Finally, the residual assigned counsel penalty yields 2.3 percentage points.  
We can conclude, that observed case characteristics play an important role in explaining the relatively worse case outcomes among indigent clients with assigned counsels. On the other hand, the influence of adverse selection is greatly dependent on the outcome variable in question. While there is some noticeable impact on the disparity of case dismissal and conviction, such effects can't be established for deferred adjudication and conditional incarceration. Further remarkable is, that adverse selection never shows the same importance as case characteristics. This is to some extent contrary to the previous work of *Iyengar* (2007) and *Roach* (2014). 

After we discussed how we can assess the gap between the unconditional assigned counsel penalty $\hat{\beta_1}^{base}$ from equation (1) and the conditional assigned counsel penalty $\hat{\beta_1}^{full}$ from equation (2) by means of decomposition, let's now make a start on the residual assigned counsel penalties. That is, since we determined the effects of case characteristics and adverse selection we are only left with matching preferences and moral hazard as the remaining causes for the remaining gap. You can now go on to the next exercise, where we start with matching preferences.  


## Exercise 3.2 -- Matching Preferences

As the authors state, part of the residual penalty could arise from the inability of indigent clients to match with attorneys based on their personal preferences. The reason behind this assumption stems from the idea, that mutual trust facilitates communication between a client and his or her attorney, which then again may help lawyers to uncover relevant facts, witnesses, alibis or extenuating circumstances regarding a case. The authors further reason, that the enhanced communication due to matching preferences could help to ensure that the defendant behaves in a way that reduces the probability that he or she will be convicted or incarcerated, such as showing up on time, showing adequate demeanor in court and refraining from suspicious activity while the case unfolds. The policy question that arises thereupon is, should indigent defendant select their own counsel in opposition to an assignment by third parties and judges. Let's try to assess this question with the help of our data. First let's look at some summary statistics in order to figure out, if there are any differences between private attorneys, which get chosen by non-indigent clients, and CJA panel attorneys, who get assigned by a third party. Note, that this tables provide an more elaborate view on the differences in attorney characteristics, that we already seen in the exercise 1.2. 

**Task:**
Simply click check and look at the tables. You can switch between them either by wiping with your mouse or clicking on the radio buttons beneath.

```{r "3_2",results='asis'}
includeHTML("preferences.html")
```

<br>
<br>
<br>


As you might have already figured out, there are substantial differences in attorney characteristics. Firstly, there seems to be an overall higher preference among non-indigent clients to retain an attorney of same race. Secondly, both, Hispanic and Black defendants are more likely to retain an attorney of the same race than to be assigned one. However, this relationship doesn't apply for white defendants. Moreover, there is a subtle preference, overall and over all races, for male attorneys. On average, the office of an appointed counsel is about seven miles further away from the resident of it's client, when compared with retained attorneys. The experience of retained attorneys exceeds the experience of assigned attorneys, both, in years and cases. Finally, clients seem to prefer to retain counsels, who are rather specialized in the category of crime the defendant is accused off.   

In the course of this exercise we will scrutinize whether revealed preferences in terms of attorney characteristics are decisive for the assigned counsel penalty. For this purpose, we will use the conditional assigned counsel penalty from equation (2) on the meanwhile well-known set of explanatory variables. In order to carry out the investigation we will add additional interaction terms to `appointed`.   

We start by examining the race dimension. We already discussed that race preferences differ along Black, Hispanic and White defendants. To account for that we will run regressions on each subgroup separately. Moreover, we will run in each subgroup two different specifications. The first specification aims at showing the average differences for a racial match relative to an attorney of a different race. The second model answers whether there is an average difference for having an attorney of each of the two other ethnicities with respect to a racial match. Because there are a total of 24 regressions (2 specifications x 3 subgroups x 4 outcomes) we will again focus on conviction as the primary outcome variable and state the results for the other outcomes afterwards. So let't get into it. 

First, we will consider the effect of black defendants being defended by black attorneys on the residual assigned counsel penalty $\hat\beta_1$ from model (2). Therefore, we will use the variable `apt_bb`, which is a dummy variable with the values 1, if the attorney is appointed and both, defendant and attorney, are black and 0 else. Note that the following few tasks replicate table 4 from the authors paper.   
The next step is to run the regression, where we add the variable `apt_bb` to the specification in equation (2). But before doing so, let's first read in the data. 

```{r "3_2__2"}
dat <- readRDS("Lawyers.rds")
```

**Task:**
Run again the model in equation (2), but with the additional interaction term added. 
The interaction term is already included in the regression code below.
Fill in the missing `subset` argument with the help of the `race` variable, which comprises the values B=Black, W=White, L=Latino/Latina (Hispanic).
Recall, that we are currently interested in the race preferences of black defendants. 

```{r "3_2__3"}
# Run the regression
fe.bb <- felm(guilty ~ appointed + apt_bb + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + white + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + racematch + caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat, subset=(___))
summary(fe.bb)
```

Firstly, note that we are unable to estimate some of the regressor coefficients. The reason for this is perfect multicollinearity, thus we will omit `hisp`, `white` and `racematch` from subsequent regressions. Either way, in the first place we are interested in the coefficients of `appointed` and `apt_bb`. While the coefficient of `appointed` represents the conditional difference in convictions between the average assigned and retained attorneys (assigned counsel penalty), the coefficient of `apt_bb` is the average conditional difference in getting assigned a black attorney as opposed to getting assigned an Hispanic or white attorney. Hence, we denote the sum of both effects as the assigned black counsel penalty, which sums up to 8 percentage points. Consequently, the difference between the assigned counsel penalty and the assigned black counsel penalty yields 1.5 percentage points. Note however, that this coefficient is not significant. 

#! start_note "Assigned Black Counsel Penalty for other Outcomes"

In order to get the results for other outcomes, we just need to change the dependent variables (and in the case of `incarcerated` further subset our data based on `guitly`)

```{r "3_2__4",results='asis'}
# Run regressions
fe.bb.dis <- felm(dismissed ~ appointed + apt_bb + male + age_offense + complaint_hist + convict_hist + hadbondsman + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat, subset=(race=="B"))


fe.bb.def <- felm(defadj ~ appointed + apt_bb + male + age_offense + complaint_hist + convict_hist + hadbondsman + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat, subset=(race=="B"))


fe.bb.inc <- felm(incarcerated ~ appointed + apt_bb + male + age_offense + complaint_hist + convict_hist + hadbondsman + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat, subset=(race=="B" & guilty==1))

# Label assigned counsel penalty and penalty of black attorney
regressor.labels <- c("Assigned", "Assigned x Black Atty")

# Output
stargazer(fe.bb.dis, fe.bb.def, fe.bb.inc, type ="html", title="Ethnicity dependent Regressions - Black Defendants", 
            covariate.labels = regressor.labels, digits=4, 
            keep = c("appointed", "apt_bb"), keep.stat = "n", star.char = c("+", "*", "**", "***"),
            order = c("appointed", "apt_bb"), star.cutoffs = c(0.1, 0.05, 0.01, 0.001),
            notes = c("+p<0.1; *p<0.05; **p<0.01; ***p<0.001"), notes.append = F)
```


---

The results for the other outcomes are analogous to the one for `guilty`. Additional on being indigent, getting an black attorney assigned as black defendant always increases the assigned counsel penalty. In the case of conditional incarceration, the coefficient on `appointed*apt_bb` suggests an additional increase of assigned counsel penalty by the factor 2. But again, all results for the additional effect are not significant. 
#! end_note


Although, the results weren't significant, we can assess the question whether black attorneys obtain less favorable outcomes among other races of defendants too. So let's run two additional regressions. In the first we add `black_appt` and `white_appt` to the regressors and subset on hispanic defendants. In the second regression we add `black_appt` and `hisp_appt` and subset on White defendants. 

**Task:**
Run both regressions. Fill in the `subset` argument with appropriately conditioning `race`. Recall, that race takes on the three values "B", "L" and "W".
The code is mostly complete, just fill in the right subsetting condition.

```{r "3_2__5",results='asis'}
# Regression on Hispanic defendants subsample
fe.lbw <- felm(guilty ~ appointed + black_appt + white_appt + male + age_offense + complaint_hist + convict_hist + hadbondsman + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat, subset=(___))

# Regression on white defendant's subsample
fe.wbl <- felm(guilty ~ appointed + black_appt + hisp_appt + male + age_offense + complaint_hist + convict_hist + hadbondsman + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat, subset=(___))

# Output
regressor.labels <- c("Assigned", "Assigned x Black Atty", "Assigned x Hisp Atty", "Assigned x White Atty")

stargazer(fe.lbw, fe.wbl, type ="html", title="Ethnicity dependent Regressions - Hispanic and White Defendants", 
            covariate.labels = regressor.labels, digits=4, 
            keep = c("appointed", "black_appt", "hisp_appt", "white_appt"), keep.stat = "n", star.char = c("+", "*", "**", "***"), order = c("appointed", "black_appt", "hisp_appt", "white_appt"), star.cutoffs = c(0.1, 0.05, 0.01, 0.001), notes = c("+p<0.1; *p<0.05; **p<0.01; ***p<0.001"), notes.append = F)

```

---


The results show that, if Hispanic defendants get assigned an Black attorney they achieve a better outcome in conviction compared to getting assigned an attorney of the same race. Contrary, if white defendants get legally represented by black assigned attorneys, they have to expect a worse outcome compared to getting assigned an white assigned attorney. But yet again the results don't have any kind of significance. Therefore, we can conclude, that while black defendants prefer to hire an attorney of the same race compared to getting assigned one, they don't benefit from that. Further we can rule out that black attorneys perform systematically worse than their colleagues. 

We could do the same analysis for Hispanic and White defendants as well, but they yield also insignificant results, hence let's skip that and put on record that the preferences we have seen in the cube of tables doesn't mirror meaningful reductions of assigned counsel penalty. You can have a look at the info box, where you find a table with all ethnicity-based regressions, if you want to reassure yourself, that this conclusion holds. 

info("Full Set of Ethnicity-based Assigned Counsel Penalty Regressions") # Run this line (Strg-Enter) to show info


Now let's do a similar assessment for the other revealed preferences, starting with the preference for male attorneys. 

**Task:** 
We begin by rescaling some variables in order to derive more sound interpretations. 
Just press `check`.

```{r "3_2__6"}
dat$reg_exp <- dat$experience/10
dat$pct_spec <- dat$percent_cases_offense_specific*100
dat$pct_appt <- dat$pct_appt*100
```


For representation purposes we will just focus on `guilty` again and begin with a regression where we add an interaction term for the variable `attymale`, which indicates the attorney's gender. Note that the authors also include the new scaled `reg_exp` as additional explanatory variable, so we will do the same. 

**Task:**
The code is already complete. Run the regression by clicking on `Check`.

```{r "3_2__7"}
# Run the Regression
fe.attymale <- felm(guilty ~ appointed + appointed*attymale + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + white + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + racematch + reg_exp +  caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat)

# Show Output
summary(fe.attymale)
```

The results show, that for indigent defendants a female attorney is hardly more favorable than a male counsel. Additionally, the result is not significant at all, thus we have no evidence to assume that attorney gender has an impact on the residual assigned counsel gap. 

We will now proceed identically for the variables `lndist`, `reg_exp`, `atty_exp` and `pct_spec` by interacting them with `appointed` and regress on the full data. Note that `reg_exp` states the decades the respective attorney is working in his profession since his or her bar admission. The `pct_spec` variable displays for every case the percentage of same offenses the attorney has dealt with in the past. Note that we will do all regressions together in the following task. 

**Task:**
The code is already complete. Run the regressions by clicking on `Check`.

```{r "3_2__8",results='asis'}
# Run all Regressions
fe.lndist <- felm(guilty ~ appointed + appointed*lndist + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + white + povrate + instability + atty_exp + pct_appt + racematch + reg_exp +  caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat)

fe.reg_exp <- felm(guilty ~ appointed + appointed*reg_exp + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + white + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + racematch + reg_exp +  caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat)

fe.atty_exp <- felm(guilty ~ appointed + appointed*atty_exp + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + white + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + racematch + reg_exp +  caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat)

fe.pct_spec <- felm(guilty ~ appointed + appointed*pct_spec + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + white + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + racematch + reg_exp +  caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat)

stargazer(fe.lndist, fe.reg_exp, fe.pct_spec, type ="html",  
            covariate.labels = c("Assigned x Log Distance", "Assigned x Experience", "Assigned x Specialization"), digits=4, 
            keep = c("appointed", "appointed*lndist", "appointed*reg_exp", "appointed*pct_spec"), keep.stat = "n", star.char = c("+", "*", "**","***"), order = c("appointed", "appointed*lndist", "appointed*reg_exp", "appointed*pct_spec"), star.cutoffs = c(0.1, 0.05, 0.01, 0.001), notes = c("+p<0.1; *p<0.05; **p<0.01; ***p<0.001"), notes.append = F)
```

The regression output shows, that the distance between an assigned attorney and his or her defendants' resident isn't significant. Years of experience however is significant at the 10% level. But remember, that we rescaled the variable by a factor of 10. Thus, the interpretation of the coefficient is, that on average 10 years of experience lead to an reduction of the residual assigned counsel penalty by 1.2 percentage points. Finally, we get highly significant results for the specialization variable, but since the magnitude of the coefficient is negligibly small offense specialization doesn't have much implications on the residual assigned counsel penalty. The same conclusion can be applied to `atty_exp`, which captures the attorney experience by the number of cases. Although the coefficient is highly significant, the effect size is rather minor. On average, assigned attorneys who have resolved 100 cases show an approximately 0.05 percentage points lower residual assigned counsel penalty. This is to some extent surprising, if we consider the overall strong preferences for attorneys with many resolved cases. If we change the outcome variable, we wouldn't obtain other results, therefore we abandon it at this point and refer to table 5 in the authors paper. 

At the end of this exercise we can conclude, that although there are some strong preferences on the private market for some attorney characteristics, they don't seem to play an important role in reducing the residual assigned counsel penalty.  
Hence, we are left with only one more possible explanation from the initial four - moral hazard, which we are going to examine in the next exercise. 

info("unobserved case characteristics as explenation for residual assigned counsel penalty") # Run this line (Strg-Enter) to show info

<div class="garbage">

info("ignore this, this is just a garbage collector for the tables cube") # Run this line (Strg-Enter) to show info
</div>



## Exercise 3.3 -- Moral Hazard

We begin by reading in the data first.

```{r "3_3"}
dat <- readRDS("Lawyers.rds")
```


Now, let's start this exercise off by recalling that the residual assigned counsel penalty is about 8.5%. This constitutes an upper bound for moral hazard. One possible explanation that underlies the issue of moral hazard could be differences in attorney compensation. According to the authors the median criminal defense attorney in San Antonio (the capital of Bexar County) charged 200$ per hour on the private market in 2015. Fees are primarily set based on the severity and complexity of the case. The authors further state, that flat fees are common in private criminal law and are set primarily on the severity and complexity of the case, e.g. possession of less than one gram of marijuana would amount to 1000-4000\$. Consequently, at an hourly rate of 200\$, a retained attorney would expect to work 5-20 hours.   
Assigned attorneys in our data have been compensated based on a fee schedule. Fees are structured in three different categories, based on the severity of offense, state jail and 3rd degree felonies, 2nd degree felonies or first degree felonies. Independent of the severity all assigned attorneys get 100$ for an initial jail visit. Further they are compensated on hourly rates for court appearance, evidentiary hearings, trials and time out of court. However, hourly rates only span the range of 50-125\$. Flat fees compose the main compensation source. However, between 2005 and 2009 only cases resolved by plea bargains or representing MTR cases (Motion to Revoke Probation) have been eligible for flat fee compensation. Resolving a case via plea bargain yielded 400-750\$ and representing MTR cases yielded 175-300\$, depending on the severity of the offense. After 2009 the flat fees have also become available for assigned attorneys who achieved the case being dismissed and increased for MTR cases. However, after 2015 all types of case resolution became eligible for flat fee compensation, which are 6% of our sample. Appointed attorneys choose the flat fee compensation in 75% of time. The reason is, according to a survey conducted by authors, that flat fee requests are not subject to review, whereas a judge can adjust, or even refuse, the hours requested by a lawyer. Another reason might be the possibility to raise the hourly wage by resolving cases faster and getting compensated by a flat fee. For example, resolve a second-degree offense case by guilty plea renders possible a 500\$ flat fee compensation, incorporating that the median private market hourly wage is 200\$, the assigned counsel would calculate to spend 2.5 hours in order to break even.  
Because of the lower compensation for assigned cases, attorneys may exert less effort and focus more on their private clients. Hence, they have an incentive to spend less time on assigned cases and may seek a fast resolution. In this light, we can assess moral hazard by using `case_length` as a proxy for lawyer effort. Case length is calculated as the difference between complaint date and the earlier of judgement date and adjudication date. Let's run a simple analysis to shortly discuss the effect of case length on being convicted. 

**Task:**
Run a simple model with `case_length` as regressor on `guilty` as dependent variable. 
Use the `lm()` function and save the result in a variable `lm.case`. 
Finally use `summary()` to produce the regression output.

```{r "3_3__2"}
# Use lm and fill in the correct syntax
lm.case <- ___
# Produce regression output
summary(___)
```

Of course, we already now, that our estimate of the `case_length` coefficient is biased, but the aim at this point is just to get an intuition of the relationship and whether it aligns with our expectations. So, the regression shows, that on average an increase in the case length by 10% yields a reduction in the predicted probability of being found guilty by 1.1 percentage points. Well, as mentioned, we shouldn't entirely trust the magnitude, but the direction of sign seems accurate. Delaying a case can lead to some benefits like unexpected testimonies or a deal with the prosecutor. Therefore, attorneys may exploit various strategies in order to delay a case, e.g. by requesting continuances for consultation purposes or for psychiatric evaluations, filing numerous motions, and using the discovery process to postpone hearings (as mentioned by the authors.) So, the natural thing to ask hereinafter is, whether there is a difference in case length between appointed and retained attorneys.   

**Task - Step 1:**
First of all, recall, that `case_length` is stated in log days. That is, we can't just calculate the mean `case_length` in both groups, appointed and retained counsels, since that wouldn't yield the arithmetic average of case length in days. Instead, first define a new variable `caselength` (and attach it to our data), that displays the case length in days, you can achieve this by applying the `exp()` function on `case_length`. 

```{r "3_3__3"}
# Specify the right-hand side of the expression
dat$caselength <- ___
```


**Task - Step 2:**
Now, calculate the `mean()` for each group of attorneys.
Note, that we follow the procedure of the authors and remove `MTR` cases from our sample first.
The code is almost complete, you just need to fill in the right `filter()` condition and the computation of the `mean()` `caselength`. 

```{r "3_3__4"}
# First, filter the data to exclude MTR cases
dat <- dat %>% filter(___)

# Now compute the average case length for each group of lawyers
dat %>% 
  group_by(appointed) %>% 
  summarize(mean_caselength=mean(caselength))

```

We obtain the result, that cases are on average 35% shorter when the counsel is assigned as opposed to retained. That seems quite significant. Of course, we need to revise this statement under consideration of case/defendant and attorney characteristics again, as we did with `guilty` as outcome variable. Hence, let's compute the conditional assigned counsel penalty with respect to `case_length`. 

**Task:**
Use the `felm()` function with the familiar set of regressors from equation (2) and the dependent variable `case_length`. 
Then apply `summary()` to the variable, where the results are stored to print the output to console. The code is already supplied, simply press `check`.

```{r "3_3__5"}
# Now run regression on case_length
fe.case_length <- felm(case_length ~ appointed + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + white + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + racematch +  caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat)

# Print regression results
summary(fe.case_length)

```

As you see, on average assigned cases get resolved 13.4 percentage points (14.4 if we use the correct log-level interpretation) faster than cases where the attorney was retained. Of course we could use `gelbach.decomposition()` function from exercise 3.1 to decompose this result, but we already know, that it takes a lot of time to run, so instead we will refer to the results from the authors. They state, that 51% of assigned counsel penalty for case length can be attributed to case characteristics and 28% are explained by adverse selection.   

Additionally, we can incorporate into our analysis that there might be a difference in case length based on the bail status. 

**Task:**
Calculate the `mean()` twice, ones for the defendants who were detained pre-adjudication and ones for the released defendants pre-adjudication.
The code is almost complete, you just need to fill in the computation of the `mean()` for `caselength`. 

```{r "3_3__6"}
# fill in the missing part in the chain
dat %>% 
  group_by(hadbondsman) %>% 
  summarize(mean_caselength=___)
```

The results show, that cases without a bail posted are 45% shorter than cases where the defendant was released pre-adjudication. 
Based on these results, let's calculate the conditional assigned counsel penalty again, ones for the subsample of no bail defendants and ones for the subsamples with bails posted. Note that in both subsamples also MTR cases stay removed. 

**Task:**
Firstly, filter the data to include only cases where bail was posted. Then run regression using `felm()` again with `case_length` as response variable, but with the new subset of data. 
Secondly, filter the data to include only cases where bail was not posted. Now run regression on this respective subsample. 
Finally print the results with `stargazer()`. 
The code is already mostly complete, you just need to accordingly `filter()` the second subsample.
Recall, that the second subsample is the one, with defendants detained. 

```{r "3_3__7",results='asis'}
# Firstly, filter the data to include only cases where bail was posted
dat_bail <- dat %>% filter(hadbondsman==1)

# Now run regression on case_length
fe.case_length_bail <- felm(case_length ~ appointed + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + white + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + racematch +  caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat_bail)

# Secondly, filter the data to include only cases where bail was not posted
dat_nobail <- dat %>% filter(___)

# Now run regression on case_length again
fe.case_length_nobail <- felm(case_length ~ appointed + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + white + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + racematch +  caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat_nobail)

# Print regression results
stargazer(fe.case_length_bail, fe.case_length_nobail, type ="html", title="Assigned Counsel Penalty of Case Length based on Bail Status", digits=4, keep = c("appointed"), keep.stat = "n", star.char = c("+", "*", "**", "***"), order = c("appointed"), star.cutoffs = c(0.1, 0.05, 0.01, 0.001), notes = c("+p<0.1; *p<0.05; **p<0.01; ***p<0.001"), notes.append = F)

```

The results show a blatant difference in the effect of bail status on case length among appointed defendants. On the one hand cases, where the attorney is assigned and the defendant is released pre-adjudication get resolved on average 13.9% faster than cases, where the attorney is retained and the defendant is released. On the other hand, cases with appointed attorneys and no posted bail endure on average 23.9% shorter than cases with retained attorneys, where no bail was posted. The reason for this disparity is the aspiration of detained defendants to get to the case resolution quickly with the potential of a favorable outcome. However, in the situation where the defendant has posted a bail, he or she has an interest in delaying case resolution, as we pointed out earlier in this exercise. The fact, that there is a significant assigned counsel penalty on case length for released defendants indicate, that the disparity is driven by attorney interest for quick case resolution, which contradicts the defendant's aspiration. This finding aligns with our discussion of the fee structures of assigned attorneys, which induce them to resolve cases faster in order to break even. 

Let's further investigate lawyer's compensation. We can exploit the circumstance that flat fee compensation changed during the sampling period of our data by assessing the implications for attorney behavior. Therefore, take a look at the image below. 

<br>

<center>

![fee_structure](fee_structure.png)

</center>
*Source: Own creation following Agan et al.*
<br>

In the case of case dismissal as outcome variable we can't observe the residual assigned counsel penalty to change on the basis of the different fee structure after July 2009. This is to some extent surprising, because the fee structure changes especially aimed at allowing flat fee compensation for dismissed cases. But it gets plausible, if we recall, that successfully completed periods of deferred adjudication results in case dismissal. Because the prosecutor will accept a deferred adjudication more likely than a immediate case dismissal the change in fee structures has a much higher impact on deferred adjudication, compared to case dismissals. Moreover, after the flat fee structure for dismissed cases was in place the assigned counsel penalty for guilty pleas notably declined. That indicates, that lawyer's behavior changes due to the compensation structure. 

The findings in this exercise suggest, that moral hazard could be well suited in explaining the gap between the outcome of retained as opposed to assigned attorneys. We found that, assigned lawyers are more likely to resolve cases faster and presumed, that compensation might be an aspect of that. Indeed, after contemplating residual assigned counsel penalties in the time before compensation structure was change in Bexar County and comparing it with the time after, we can find remarkable shifts in assigned counsel gaps for the outcomes sensitive to the change. 



## Exercise 4 -- Investigating Recidivism 

You know it, the first thing to do is, reading in the data.

**Task:**
Read in the data by clicking `check`.

```{r "4"}
dat <- readRDS("Lawyers.rds")
```

In the final exercise we will assess the implications of the assigned counsel penalty on recidivism of defendants. Therefore, we will consider **attorney-specific** assigned counsel penalties and their impacts on the future recidivism of clients. Because we identify attorneys distinctly by `attybarcard`, but the bar numbers aren't so convenient to handle, let's change them to a consecutive numbering. 

**Task:**
Generate a consecutive numbering of Lawyers, save it in a variable `atty` and attach it to the data.
One way to do this, is by utilizing the `cumsum()` and `diff()` function.   
If we apply `diff()` on the ordered vector `attybarcard`, we get a value of one always when another attorney appears in the data. The `cumsum()` function returns the accumulated sum vector, which has the same length as our data, if we additionally add a 1 at the start (since the `diff()` is not defined for the first row).   
The code is already provided, just press `check`.

```{r "4__2"}
# Define consecutive numbering of lawyers
dat$atty <- cumsum(c(1,diff(dat$attybarcard) != 0))

```

The following steps will guide you through the process in order to replicate figure 4 from the authors paper, which shows the linear relationship between the attorney-specific assigned counsel penalty and the probability that an attorney's client recidivates. Note that we will focus on the code first and give an interpretation of the resulting figure afterwards.

**Task - Step 1:**
Firstly, change `atty` to `class` `factor`.
Secondly, rerun the model specification stated in (2) with the supplement of adding interaction terms, between `appointed` and `atty`. Finally, show the output as always with `summary()`.
The code is already provided, just press `check`.   
Note, that the computation takes some time.

```{r "4__3"}
# Convert numeric to factor
dat$atty <- factor(dat$atty)

# Run regression with attorney-specific fixed effects
fe.atty <- felm(guilty ~ appointed:atty + male + age_offense + complaint_hist + convict_hist + hadbondsman + hisp + white + povrate + instability + log(distance_to_atty) + atty_exp + pct_appt + racematch +  caseload_retained | atty_year + offense_num + court_docket | 0 | attybarcard, exactDOF = T, cmethod="reghdfe", data=dat)

# Show output
summary(fe.atty)

```

The regression output shows for some attorneys `NA`. As we discussed previously, there has to be variation in assigned and retained cases within attorneys (and years). If there is no variation they don't contribute to the estimation and hence are labelled with `NA`. 


**Task - Step 2:**
Now let's save all coefficients that we obtained from the last regression in our data. We want to match each attorney-specific coefficient to the respective attorney. 
Use the `dplyr` functions `group_by()` and `mutate()` to achieve this. 
While the argument to `mutate()` is already provided, you need to fill in the right argument for `group_by()`.   
Finally, show the results with the help of `distinct()` from `dplyr` which shows all unique values of the specified variables.

```{r "4__4"}
# Group by atty in order to assign each attorney his or her corresponding coefficient
dat <- dat %>% 
  group_by(___) %>% 
  mutate(attybeta = fe.atty$coefficients[-c(1:14),][atty])

# Show results with distinct
distinct(dat, atty, attybeta)
```

**Task - Step 3:**
Now run a regression with `recidicism3` as dependent variable, which takes the value 1, if the defendant gets charged with a felony again within three years and 0 else. The explanatory variables are provided in the chunk. Note, that we specify the `subset` argument of the `lm()` function such that only defendants who hasn't been incarcerated get considered in the regression.

```{r "4__5"}
# Now run the linear model (already completely provided)
recid3 <- lm(formula = ___ ~ male + age_offense + complaint_hist + convict_hist + 
    hadbondsman + race + povrate + instability, data=dat, subset=incarcerated==0)

# Print Output
summary(recid3)
```

**Task - Step 4:**
This step calculates the residuals for all cases in our **complete** sample of all 64209 cases. 
To achieve this we use the `predict()` function to calculate the fitted values from the model `recid3`. 
Afterwards, we compute the difference between the observed values `recidivism3` and the fitted values.
The solution is attached to our data. We also add a column `resid_appt` to our data, where we save the residual, if the observation was used in model estimation and the attorney is assigned.
Click on `check` to run the chunk.   

```{r "4__6"}
# Compute residuals
dat$recid_resid <- dat$recidivism3-predict(recid3, dat)

# Define additional variable with residuals, if certain conditions are fulfilled
dat$resid_appt <- ifelse(dat$appointed==1 & dat$incarcerated==0, dat$recid_resid, NA)
```

**Task - Step 5:**
In this chunk the mean residuals get averaged for each attorney. Further, we compute the assignment rate for each attorney and append the solution to our data with `mutate()`. 
Just press `check`. 

```{r "4__7"}
# Compute the mean residuals for each attorney
dat <- dat %>% 
  group_by(atty) %>% 
  mutate(mean_resid_appt = mean(resid_appt, na.rm=T),
         
         # Compute the Assignment rate
         shr_assigned = mean(appointed))
```

**Task - Step 6:**
Because we want to use a weighted least squares regression in the next step, we need to determine the weights first. We do this by using `shr_assigned` from the last computation and multiply it with `1-shr_assigned`. By this, we reassure that attorneys who have a balanced share of retained and assigned cases get higher weights. The maximum weight is 0.25, reserved for attorneys with equal retained and assigned cases and the minimum is 0, reserved for counsels with only retained or assigned cases. We also require the total amount of cases handled by each attorney, `atty_n`. The chunk already contains the complete code, so click on `check` and continue. 

```{r "4__8"}
# Define weights
dat$shr_assigned_i <- dat$shr_assigned*(1 - dat$shr_assigned)

# Define total case number for each attorney
dat <- dat %>% 
  group_by(atty) %>% 
  mutate(atty_n = row_number())
```

**Task - Step 7:**
In this step we will run the weighted least squares regression. 
We calculated the weights already in the last step. 
The dependent variable is the vector of mean residuals for assigned cases `mean_resid_appt` and the independent variable is the vector of attorney-specific residual assigned counsel penalties, `attybeta`, calculated in the steps 1 and 2. 
Before we run the regression, we subset our data such that it only includes each attorney ones. 
Finally, save the coefficients from the regression.

```{r "4__9"}
# Filter Data (one row for each attorney)
dat <- dat %>% filter(atty_n==1)

# Run regression
wls <- lm(mean_resid_appt ~ attybeta, data = dat, weights = shr_assigned_i)

# Extract Estimates
beta0 <- wls$coefficients[1]
beta1 <- wls$coefficients[2]

# Provide regression output
summary(wls)
```

**Task - Step 8:**
Click on `check` to show the plot.

```{r "4__10",results='asis', output='htmlwidget', widget='rbokeh', optional=TRUE}
# Firstly, load the package rbokeh
library(rbokeh)

# Secondly, produce the plot
figure(title="Attorney-Specific Assigned Counsel Penalties Impact on Recidivism", xlab="Residual Assigned Counsel Penalty", ylab="Probability of Recidivism", ylim=c(-0.5,1), width = 1500, height=1200, legend_location = NULL) %>%
  ly_points(x = attybeta, y = mean_resid_appt, data = dat, color=experience, fill_color= c("#337ab7"), line_color="black", 
            alpha=0.5, size=shr_assigned_i, hover = list(attybarcard, attymale, atty_exp)) %>% 
  ly_abline(wls, width = 2)

```

The plot shows the regression result, that we obtained from step 6. Accordingly, there is a positive and significant relationship between the attorney-specific assigned counsel penalty and the residualized recidivism of their assigned clients. Remember, that we computed the recidivism rate by first running the variable `recidivism3` as response in step 3. The residuals, that we got thereafter in step 4 depict the left-over variation in the error term after we accounted for case characteristics. We then took the mean within each attorney and over all cases with indigent accused. Hence the plot implies that, we can expect a client to face a higher probability of recidivism if he gets assigned an attorney with relative high attorney-specific assigned counsel penalty. 


## Exercise 5 -- Conclusion


At first, let's sum up, what we learned about the Selection and Success of Lawyers. We saw, that attorneys who get assigned an indigent client achieve results that fall short compared to the outcomes which retained counsels achieve for their clients. Based on the ideas of the authors we considered four possible reasons that could explain this disparity: case characteristics, adverse selection, matching preferences and moral hazard. Thereupon we used the main model proposed by the authors, which we stated in equation (2) to assess the impact of case characteristics and adverse selection on the outcome, whereat we primarily focused on conviction as the outcome of interest. Thereby, we used the unique features of our data at hand to identify the residual assigned counsel penalty based on similar cases that lawyers resolved during a year as appointed and retained attorneys. Afterwards we implemented the Gelbach decomposition into our own function, to assess the disparity between the unconditional and conditional assigned counsel penalty and found that adverse selection plays a minor part compared to case characteristics. Although, case characteristics aren't solely responsible for the disparity. Finally, we investigated how matching preferences and moral hazard could help explain the residual assigned counsel penalty. While we concluded, that matching preferences play a negligible role, there was some evidence supporting the relevance of moral hazard to explain the remaining gap between retained and assigned attorneys. We found that appointed attorneys resolve cases faster which is driven by the compensation structure and contributes to the residual assigned counsel gap. Eventually, we also took a look at recidivism in order to understand why assigned counsel penalty is a relevant issue.

At second, during the exercises we learned basic data manipulation techniques with `dplyr` package. Then, we recalled how to run simple models with the help of `lm()`. Afterwards we saw how we can use the `felm()` function from the `lfe` package to estimate models with a high number of dummy variables. Besides data manipulation and estimation, we also explored data visualization methods like the `ggplot2` package and `rbokeh`. 

I hope you enjoyed this problem set and gained some useful insights into the topic of selection and success of lawyers.


If you want to see the awards you earned during the problem set, you can run the following code chunk. 

```{r "5"}
awards()
```

## Exercise References 

### Bibliography

- *Agan, A., Freedman, M. & Owens, E.* (2018): Is your lawyer a lemon? Incentives and selection in the public provision of criminal defense. NBER Working Paper No. 24579,https://www.nber.org/papers/w24579.
- *Agan, A., Freedman, M. & Owens, E.* (2019): Is your lawyer a lemon? Incentives and selection in the public provision of criminal defense. Review of Economics and Statistics, 1-51.
- *Abrams, D. S. & Yoon, A. H.* (2007). The luck of the draw: Using random case assignment to investigate attorney ability. The University of Chicago Law Review, 74(4), 1145-1177.
- *Angrist, J. D. & Pischke, J. S.* (2008): Mostly harmless econometrics: An empiricist's companion. Princeton university press.
- *Arellano, M.* (1987): Computing Robust Standard Errors for Within-Group Estimators, Oxford Bulletin of Economics and Statistics, 49, 431-434.
- *Cameron, A. C. & Miller, D. L.* (2015): A practitioners guide to cluster-robust inference. Journal of human resources, 50(2), 317-372.
- *Cameron, A. C., Gelbach, J. B. & Miller, D. L.* (2008): Bootstrap-based improvements for inference with clustered errors. The Review of Economics and Statistics, 90(3), 414-427.
- *Cameron, A. C., Gelbach, J. B. & Miller, D. L.* (2011): Robust inference with multiway clustering. Journal of Business & Economic Statistics, 29(2), 238-249. 
- *Chang, W* (2020): R Graphics Cookbook. O'Reilly Media.
- *Cohen, T. H.* (2014): Who is better at defending criminals? Does type of defense attorney matter in terms of producing favorable case outcomes. Criminal Justice Policy Review, 25(1), 29-58.
- *Correia, S.* (2015): Singletons, cluster-robust standard errors and fixed effects: A bad mix. Technical Note, Duke University.
- *Gaure, S.* (2013a): lfe: Linear group fixed effects. The R Journal, 5(2), 104-117.
- *Gaure, S.* (2013b): OLS with multiple high dimensional category variables. Computational Statistics & Data Analysis, 66, 8-18.
- *Gelbach, J. B.* (2016): When do covariates matter? And which ones, and how much?, Journal of Labor Economics, 34(2), 509-543.
- *Gideon v. Wainwright*, 372 U.S. 335 (1963).
- *Iyengar, R* (2007): An Analysis of the Performance of Federal Indigent Counsel. NBER Working Paper No. 13187, [http://www.nber.org/papers/w13187](http://www.nber.org/papers/w13187).
- *Moulton, B.R.* (1986): Random Group Effects and the Precision of Regression Estimates, Journal of Econometrics, 32, 385-397.
- *Moulton, B.R.* (1990): An Illustration of a Pitfall in Estimating the Effects of Aggregate Variables on Micro Units, Review of Economics and Statistics, 72, 334-38.
- *Newey, W. K. & Kenneth, D. West.* (1987): A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix, 55. Econometrica, 703-8.
- *Neyman, J.* (1923/1990): On the application of probability theory to agricultural experiments. Essay on principles. Section 9. Statistical Science, 5, 465-472.
- *Paradis, E.* (2005): R for Beginners, CRAN eBook, https://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf.
- *Prabhakaran, S* (2016): r-statistics.co. http://r-statistics.co.
- *Roach, M. A.* (2014): Indigent defense counsel, attorney quality, and defendant outcomes. American Law and Economics Review, 16(2), 577-619.
- *White, H.* (1980): A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. Econometrica: journal of the Econometric Society, 817-838.
- *White, H.* (1984): Asymptotic Theory for Econometricians, Academic Press.


### R Packages and other Programming Tools

- *Kharlampidi, V.* (2020): swiper version 5.4.1, https://swiperjs.com. 
- *Gaure, S.* (2019): lfe: Linear Group Fixed Effects. https://CRAN.R-project.org/package=lfe.
- *Hlavac, M.* (2018): stargazer: Well-Formatted Regression and Summary Statistics Tables. R package version 5.2.1. https://CRAN.R-project.org/package=stargazer.
- *Wickham, H.* (2016): ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. ISBN 978-3-319-24277-4, https://ggplot2.tidyverse.org.
- *Wickham, H., Francois, R., Henry, L. & Muller, K.* (2018): dplyr. "A Grammar of Data Manipulation", R package version 0.7.7, http://CRAN.R-project.org/package=dplyr.
- *R Development Core Team* (2015): R. "A language and environment for statistical computing", R Foundation for Statistical Computing, Vienna, Austria, http://www.r-project.org.
- *Kranz, S.* (2015): RTutor. "Creating R problem sets with automatic assessment of student's solutions", R package version 2015.12.16, https://github.com/skranz/RTutor.
- *Wickham, H. and Henry, L.* (2020): tidyr: Tidy Messy Data. R package version 1.0.2. https://CRAN.R-project.org/package=tidyr.
- *Xie, Y* (2020): knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.28.
- *Dowle, M. & Srinivasan, A.* (2019): data.table: Extension of `data.frame`. R package version 1.12.8. https://CRAN.R-project.org/package=data.table.
- *Brown, C.* (2012): dummies: Create dummy/indicator variables flexibly and efficiently. R package version 1.5.6. https://CRAN.R-project.org/package=dummies.
- *Hafen, R. & Continuum Analytics, Inc.* (2016): rbokeh: R Interface for Bokeh. R package version 0.5.0. https://CRAN.R-project.org/package=rbokeh. 
- *Chang, W* (2018): shinythemes: Themes for Shiny. R package version 1.1.2. https://CRAN.R-project.org/package=shinythemes.

